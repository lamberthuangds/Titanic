{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.client import device_lib\n",
    "model_path = '/home/lambert/Git/Titanic/Titanic_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_title(name):\n",
    "    if pd.isnull(name):\n",
    "        return 'Null'\n",
    "    title_search = re.search('([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1).lower()\n",
    "    else:\n",
    "        return 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = {'mr':1, 'mrs':2, 'mme':2, 'ms':3, 'miss':3, 'mlle':3, 'don':4, 'sir':4, 'jonkheer':4,\n",
    "          'major':4, 'col':4, 'dr':4, 'master':4, 'capt':4, 'dona':5, 'lady':5, 'countess':5,\n",
    "         'rev':6}\n",
    "df_train['Title'] = df_train['Name'].apply(lambda name: titles.get(get_title(name)))\n",
    "df_train['Honor'] = df_train['Title'].apply(lambda title: 1 if title ==4 or title == 5 else 0)\n",
    "df_test['Title'] = df_test['Name'].apply(lambda name: titles.get(get_title(name)))\n",
    "df_test['Honor'] = df_test['Title'].apply(lambda title: 1 if title ==4 or title == 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/pandas/core/indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# 1. Data clearning\n",
    "# df_train.Age.fillna(fill_df_Age, inplace=True)\n",
    "# df_test.Age.fillna(fill_df_Age, inplace=True)\n",
    "for i in range(1,7):\n",
    "    a = df_train[(df_train.Age.isnull()) & (df_train.Title==i)]\n",
    "    df_train.Age.iloc[a.index] = df_train.Age[df_train.Title==i].median()\n",
    "    b = df_test[(df_test.Age.isnull()) & (df_test.Title==i)]\n",
    "    df_test.Age.iloc[b.index] = df_train.Age[df_train.Title==i].median()\n",
    "\n",
    "# Cabin - fill nan with 'fill' and select first cabin\n",
    "df_train.Cabin.fillna('fill',inplace=True)\n",
    "df_train.Cabin = df_train.Cabin.map(lambda x:x.split(' ')[0])\n",
    "df_test.Cabin.fillna('fill', inplace=True)\n",
    "df_test.Cabin = df_test.Cabin.map(lambda x:x.split(' ')[0])\n",
    "\n",
    "# Sex - male: 1, female: 1\n",
    "df_train.Sex.replace({'male':1, 'female':0}, inplace=True)\n",
    "df_test.Sex.replace({'male':1, 'female':0}, inplace=True)\n",
    "\n",
    "df_train = df_train.dropna(axis=0, how='any')\n",
    "df_test.Fare.fillna(df_test.Fare.mean(), inplace=True)\n",
    "\n",
    "# Create a 'Deceased' column for sconed class\n",
    "df_train['Deceased'] = df_train.Survived.apply(lambda s: int(not s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Select the features\n",
    "sFeatures = ['Pclass',\n",
    " 'Sex',\n",
    " 'Age',\n",
    " 'SibSp',\n",
    " 'Parch',\n",
    " 'Fare',             \n",
    " 'Cabin',             \n",
    " 'Embarked',\n",
    " 'Title',\n",
    " 'Honor']\n",
    "\n",
    "X = df_train[sFeatures]\n",
    "y = df_train[['Survived','Deceased']]\n",
    "y = y.values.reshape(len(y),2)\n",
    "X_test = df_test[sFeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# 3. Label Encoder\n",
    "# X_test has elements that X doesn't have\n",
    "# create a Cabin_labels cover X and X_test\n",
    "X_Cabin_unique = X['Cabin'].unique()\n",
    "X_lack = X_test.Cabin[X_test['Cabin'].isin(X_Cabin_unique)==0].values\n",
    "Cabin_labels = np.append(X_Cabin_unique, X_lack)\n",
    "# print(X_Cabin_unique.shape, X_Cabin_unique)\n",
    "# print(Cabin_labels.shape, Cabin_labels)\n",
    "\n",
    "le_Cabin = LabelEncoder().fit(Cabin_labels)\n",
    "le_Embarked = LabelEncoder().fit(np.array(X['Embarked'].tolist()))\n",
    "\n",
    "X.loc[:,'Cabin'] = le_Cabin.transform(X['Cabin'])\n",
    "X.loc[:,'Embarked'] = le_Embarked.transform(X['Embarked'])\n",
    "X_test.loc[:,'Cabin'] = le_Cabin.transform(X_test['Cabin'])\n",
    "X_test.loc[:,'Embarked'] = le_Embarked.transform(X_test['Embarked'])\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Validation\n",
    "X_train = X\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(batch, X, y):\n",
    "    num = np.arange(len(X))\n",
    "    np.random.shuffle(num)\n",
    "    select = num[0:batch]\n",
    "    x_batch = X.iloc[select]\n",
    "    y_batch = y[select]\n",
    "    \n",
    "    return(x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    total_loss = 0\n",
    "    for i in range(num_iterations):\n",
    "        x_batch, y_batch = next_batch(batch_size, X_train_data, y_train_data)\n",
    "        feed_dict_train = {X_place: x_batch, y_place: y_batch}\n",
    "        _, loss = sess.run([train_op, cost], feed_dict=feed_dict_train)\n",
    "        total_loss += loss\n",
    "        print('Epoch: {:04d}, total loss={:.9f}'.format(epoch+1, total_loss))\n",
    "    print ('Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow variables\n",
    "# with tf.device('/device:GPU:0'):\n",
    "features= len(sFeatures)\n",
    "X_place = tf.placeholder(tf.float32, shape=[None,features])\n",
    "y_place = tf.placeholder(tf.float32, shape=[None,2])\n",
    "W = tf.Variable(tf.random_normal([features, 2]), name='weights')\n",
    "b = tf.Variable(tf.zeros(2), name='bias')\n",
    "logits = tf.matmul(X_place, W) + b\n",
    "y_pred = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Entropy\n",
    "# with tf.device('/device:GPU:0'):\n",
    "learning_rate = 0.001\n",
    "cross_entropy = -tf.reduce_sum(y_place * tf.log(y_pred + 1e-10), axis=1)\n",
    "# cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y_train)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.Session()\n",
    "# sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training starting option 1\n",
    "# for epoch in range(1000):\n",
    "#     total_loss = 0.\n",
    "#     x_batch, y_batch = next_batch(batch_size, X_train, y_train)\n",
    "#     feed_dict_train = {X_place: x_batch, y_place: y_batch}\n",
    "#     _, loss = sess.run([train_op, cost], feed_dict=feed_dict_train)\n",
    "#     total_loss += loss\n",
    "#     print('Epoch: {:04d}, total loss={:.9f}'.format(epoch+1, total_loss))\n",
    "# #     print('Epoch: {:04d}, total loss={:.9f}, entropy: {}'.format(epoch+1, total_loss, cross_entropy))\n",
    "# #     print('predict: {:.6f}'.format(y_pred))\n",
    "# print ('Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training starting option 1 with CPU\n",
    "# for epoch in range(100):\n",
    "#     total_loss = 0.\n",
    "#     for i in range(len(X_train)):\n",
    "#         feed = {X_place: X_train, y_place: y_train}\n",
    "#         _, loss = sess.run([train_op, cost], feed_dict=feed)\n",
    "#         total_loss += loss\n",
    "#     print('Epoch: {:04d}, total loss={:.9f}'.format(epoch+1, total_loss))\n",
    "# #     print('Epoch: {:04d}, total loss={:.9f}, entropy: {}'.format(epoch+1, total_loss, cross_entropy))\n",
    "# #     print('predict: {:.6f}'.format(y_pred))\n",
    "# print ('Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation 'init': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: init = NoOp[_device=\"/device:GPU:0\"](^weights/Assign, ^bias/Assign, ^weights_1/Assign, ^bias_1/Assign)]]\n\nCaused by op 'init', defined at:\n  File \"/Users/lambert/miniconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/lambert/miniconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/lambert/miniconda3/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/Users/lambert/miniconda3/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"/Users/lambert/miniconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-35b0c366c272>\", line 7, in <module>\n    sess.run(tf.global_variables_initializer())\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1569, in global_variables_initializer\n    return variables_initializer(global_variables())\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1546, in variables_initializer\n    return control_flow_ops.group(*[v.initializer for v in var_list], name=name)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3349, in group\n    return _GroupControlDeps(dev, deps, name=name)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3295, in _GroupControlDeps\n    return no_op(name=name)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_control_flow_ops.py\", line 499, in no_op\n    \"NoOp\", name=name)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'init': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: init = NoOp[_device=\"/device:GPU:0\"](^weights/Assign, ^bias/Assign, ^weights_1/Assign, ^bias_1/Assign)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1309\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n",
      "\u001b[0;32m~/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1357\u001b[0m             tf_session.TF_ExtendGraph(self._session,\n\u001b[0;32m-> 1358\u001b[0;31m                                       graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1359\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'init': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: init = NoOp[_device=\"/device:GPU:0\"](^weights/Assign, ^bias/Assign, ^weights_1/Assign, ^bias_1/Assign)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-57a05870887e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_device_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/device:CPU:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'init': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: init = NoOp[_device=\"/device:GPU:0\"](^weights/Assign, ^bias/Assign, ^weights_1/Assign, ^bias_1/Assign)]]\n\nCaused by op 'init', defined at:\n  File \"/Users/lambert/miniconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/lambert/miniconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/lambert/miniconda3/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/Users/lambert/miniconda3/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"/Users/lambert/miniconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-35b0c366c272>\", line 7, in <module>\n    sess.run(tf.global_variables_initializer())\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1569, in global_variables_initializer\n    return variables_initializer(global_variables())\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1546, in variables_initializer\n    return control_flow_ops.group(*[v.initializer for v in var_list], name=name)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3349, in group\n    return _GroupControlDeps(dev, deps, name=name)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3295, in _GroupControlDeps\n    return no_op(name=name)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_control_flow_ops.py\", line 499, in no_op\n    \"NoOp\", name=name)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'init': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: init = NoOp[_device=\"/device:GPU:0\"](^weights/Assign, ^bias/Assign, ^weights_1/Assign, ^bias_1/Assign)]]\n"
     ]
    }
   ],
   "source": [
    "# training starting option 1 with GPU\n",
    "# with tf.device('/device:GPU:0'):\n",
    "start = time.time()\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(6000):\n",
    "            total_loss = 0.\n",
    "            for i in range(len(X_train)):\n",
    "                feed = {X_place: X_train, y_place: y_train}\n",
    "                _, loss = sess.run([train_op, cost], feed_dict=feed)\n",
    "                total_loss += loss\n",
    "            print('Epoch: {:04d}, total loss={:.9f}'.format(epoch+1, total_loss))\n",
    "        #     print('Epoch: {:04d}, total loss={:.9f}, entropy: {}'.format(epoch+1, total_loss, cross_entropy))\n",
    "        #     print('predict: {:.6f}'.format(y_pred))\n",
    "        print ('Training complete!')\n",
    "\n",
    "        feed_dict_train = {X_place: X_val}\n",
    "        prediction = sess.run(y_pred, feed_dict=feed_dict_train)\n",
    "        correct = np.equal(np.argmax(prediction,axis=1), np.argmax(y_val,axis=1))\n",
    "        # evaluate the accuracy\n",
    "        accuracy = np.mean(correct)\n",
    "        print('Accuracy on validation: {:2.2%}'.format (accuracy))\n",
    "    save_path = saver.save(sess, model_path+'Titanic_model.ckpt')\n",
    "end = time.time()\n",
    "print('time spend: {:.4f} sec'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary to dir for TensorBoard\n",
    "# tensorboard --logdir \"/Users/lambert/Documents/Python_code/ML_framework/iris_model\"\n",
    "with tf.Session() as sess:\n",
    "    File_Writer=tf.summary.FileWriter(model_path, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = saver.save(sess, model_path+'Titanic_model.ckpt')\n",
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/lambert/Git/Titanic/Titanic_model/Titanic_model.ckpt\n",
      "Accuracy on validation: 82.56%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the training data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path+'Titanic_model.ckpt')\n",
    "    feed_dict_train = {X_place: X_train}\n",
    "    prediction = sess.run(y_pred, feed_dict=feed_dict_train)\n",
    "    correct = np.equal(np.argmax(prediction,axis=1), np.argmax(y_train,axis=1))\n",
    "# evaluate the accuracy\n",
    "accuracy = np.mean(correct)\n",
    "print('Accuracy on validation: {:2.2%}'.format (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/lambert/Git/Titanic/Titanic_model/Titanic_model.ckpt\n",
      "Accuracy on validation: 74.89%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the validate data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path+'Titanic_model.ckpt')\n",
    "    feed_dict_valid = {X_place: X_val}\n",
    "    prediction = sess.run(y_pred, feed_dict=feed_dict_valid)\n",
    "    correct = np.equal(np.argmax(prediction,axis=1), np.argmax(y_val,axis=1))\n",
    "# evaluate the accuracy\n",
    "\n",
    "accuracy = np.mean(correct)\n",
    "print('Accuracy on validation: {:2.2%}'.format (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/lambert/Git/Titanic/Titanic_model/Titanic_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# prediction for test data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path+'Titanic_model.ckpt')\n",
    "    feed_dict_test = {X_place: X_test}\n",
    "    prediction = sess.run(y_pred, feed_dict=feed_dict_test)\n",
    "    y_predict = np.argmax(prediction, axis=1)\n",
    "    y_predict_1 = np.argmin(prediction, axis=1)\n",
    "    \n",
    "# evaluate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengerid = np.array(df_test.PassengerId.tolist())\n",
    "submission = pd.DataFrame({'PassengerId': passengerid, 'Survived': y_predict_1}).set_index('PassengerId')\n",
    "submission.to_csv('submission_tf_GDO_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_accuracy()\n",
    "# plot_example_errors()\n",
    "# optimize(num_iterations=10)\n",
    "# print_accuracy()\n",
    "# plot_example_errors()\n",
    "# plot_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lambert/Git/Titanic/'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path.split('Titanic_model')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "File_Writer=tf.summary.FileWriter(model_path.split('Titanic_model')[0], sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "# with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate as much GPU memory based on runtime allocations\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate 40% memory of GPU\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "# session = tf.Session(config=config, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically choose existing in case specified one doesn't exit\n",
    "# allow_soft_placement=True\n",
    "# with tf.device('/device:GPU:2'):\n",
    "#   a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "#   b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "#   c = tf.matmul(a, b)\n",
    "# # Creates a session with allow_soft_placement and log_device_placement set\n",
    "# # to True.\n",
    "# sess = tf.Session(config=tf.ConfigProto(\n",
    "#       allow_soft_placement=True, log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 3012004715058479259, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 18415616\n",
       " locality {\n",
       "   bus_id: 1\n",
       " }\n",
       " incarnation: 1414880434492412731\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "# lr = LogisticRegression(C=1, max_iter=100, solver='lbfgs').fit(X_train, y_train)\n",
    "# yp = lr.predict(X_train)\n",
    "# y_predict = lr.predict(X_test)\n",
    "\n",
    "# passengerid = np.array(df_test.PassengerId.tolist())\n",
    "# submission = pd.DataFrame({'PassengerId': passengerid, 'Survived': y_predict}).set_index('PassengerId')\n",
    "# submission.to_csv('submission_knn.csv')\n",
    "# passengerid = np.array(df_train.PassengerId.tolist())\n",
    "# submission = pd.DataFrame({'PassengerId': passengerid, 'Survived': yp}).set_index('PassengerId')\n",
    "# submission.to_csv('y_train_predict.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting Classifier\n",
    "# gbdt = GradientBoostingClassifier(n_estimators=300, max_depth=5).fit(X_train, y_train)\n",
    "# y_predict = gbdt.predict(X_test)\n",
    "\n",
    "# passengerid = np.array(df_test.PassengerId.tolist())\n",
    "# submission = pd.DataFrame({'PassengerId': passengerid, 'Survived': y_predict}).set_index('PassengerId')\n",
    "# submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "# rfc = RandomForestClassifier(n_estimators=200, max_depth=3).fit(X_train, y_train)\n",
    "# y_predict = rfc.predict(X_test)\n",
    "# passengerid = np.array(df_test.PassengerId.tolist())\n",
    "# submission = pd.DataFrame({'PassengerId': passengerid, 'Survived': y_predict}).set_index('PassengerId')\n",
    "# submission.to_csv('submission_random.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent (SDG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent (SGD) easily scale with more than 10^5 samples and features\n",
    "# sgd = SGDClassifier(alpha=0.01, max_iter=1000).fit(X_train, y_train)\n",
    "# y_predict = sgd.predict(X_test)\n",
    "# passengerid = np.array(df_test.PassengerId.tolist())\n",
    "# submission = pd.DataFrame({'PassengerId': passengerid, 'Survived': y_predict}).set_index('PassengerId')\n",
    "# submission.to_csv('submission_sdg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
