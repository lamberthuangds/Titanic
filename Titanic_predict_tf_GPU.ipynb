{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lambert/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.client import device_lib\n",
    "model_path = '~/Git/Titanic/Titanic_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_title(name):\n",
    "    if pd.isnull(name):\n",
    "        return 'Null'\n",
    "    title_search = re.search('([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1).lower()\n",
    "    else:\n",
    "        return 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = {'mr':1, 'mrs':2, 'mme':2, 'ms':3, 'miss':3, 'mlle':3, 'don':4, 'sir':4, 'jonkheer':4,\n",
    "          'major':4, 'col':4, 'dr':4, 'master':4, 'capt':4, 'dona':5, 'lady':5, 'countess':5,\n",
    "         'rev':6}\n",
    "df_train['Title'] = df_train['Name'].apply(lambda name: titles.get(get_title(name)))\n",
    "df_train['Honor'] = df_train['Title'].apply(lambda title: 1 if title ==4 or title == 5 else 0)\n",
    "df_test['Title'] = df_test['Name'].apply(lambda name: titles.get(get_title(name)))\n",
    "df_test['Honor'] = df_test['Title'].apply(lambda title: 1 if title ==4 or title == 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lambert/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# 1. Data clearning\n",
    "# df_train.Age.fillna(fill_df_Age, inplace=True)\n",
    "# df_test.Age.fillna(fill_df_Age, inplace=True)\n",
    "for i in range(1,7):\n",
    "    a = df_train[(df_train.Age.isnull()) & (df_train.Title==i)]\n",
    "    df_train.Age.iloc[a.index] = df_train.Age[df_train.Title==i].median()\n",
    "    b = df_test[(df_test.Age.isnull()) & (df_test.Title==i)]\n",
    "    df_test.Age.iloc[b.index] = df_train.Age[df_train.Title==i].median()\n",
    "\n",
    "# Cabin - fill nan with 'fill' and select first cabin\n",
    "df_train.Cabin.fillna('fill',inplace=True)\n",
    "df_train.Cabin = df_train.Cabin.map(lambda x:x.split(' ')[0])\n",
    "df_test.Cabin.fillna('fill', inplace=True)\n",
    "df_test.Cabin = df_test.Cabin.map(lambda x:x.split(' ')[0])\n",
    "\n",
    "# Sex - male: 1, female: 1\n",
    "df_train.Sex.replace({'male':1, 'female':0}, inplace=True)\n",
    "df_test.Sex.replace({'male':1, 'female':0}, inplace=True)\n",
    "\n",
    "df_train = df_train.dropna(axis=0, how='any')\n",
    "df_test.Fare.fillna(df_test.Fare.mean(), inplace=True)\n",
    "\n",
    "# Create a 'Deceased' column for sconed class\n",
    "df_train['Deceased'] = df_train.Survived.apply(lambda s: int(not s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Select the features\n",
    "sFeatures = ['Pclass',\n",
    " 'Sex',\n",
    " 'Age',\n",
    " 'SibSp',\n",
    " 'Parch',\n",
    " 'Fare',             \n",
    " 'Cabin',             \n",
    " 'Embarked',\n",
    " 'Title',\n",
    " 'Honor']\n",
    "\n",
    "X = df_train[sFeatures]\n",
    "y = df_train[['Survived','Deceased']]\n",
    "y = y.values.reshape(len(y),2)\n",
    "X_test = df_test[sFeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lambert/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# 3. Label Encoder\n",
    "# X_test has elements that X doesn't have\n",
    "# create a Cabin_labels cover X and X_test\n",
    "X_Cabin_unique = X['Cabin'].unique()\n",
    "X_lack = X_test.Cabin[X_test['Cabin'].isin(X_Cabin_unique)==0].values\n",
    "Cabin_labels = np.append(X_Cabin_unique, X_lack)\n",
    "# print(X_Cabin_unique.shape, X_Cabin_unique)\n",
    "# print(Cabin_labels.shape, Cabin_labels)\n",
    "\n",
    "le_Cabin = LabelEncoder().fit(Cabin_labels)\n",
    "le_Embarked = LabelEncoder().fit(np.array(X['Embarked'].tolist()))\n",
    "\n",
    "X.loc[:,'Cabin'] = le_Cabin.transform(X['Cabin'])\n",
    "X.loc[:,'Embarked'] = le_Embarked.transform(X['Embarked'])\n",
    "X_test.loc[:,'Cabin'] = le_Cabin.transform(X_test['Cabin'])\n",
    "X_test.loc[:,'Embarked'] = le_Embarked.transform(X_test['Embarked'])\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Honor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.879200</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.050000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.633301</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.483300</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.012500</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex   Age  SibSp  Parch        Fare  Cabin  Embarked  Title  \\\n",
       "28      3.0  0.0  21.0    0.0    0.0    7.879200  180.0       1.0    3.0   \n",
       "178     2.0  1.0  30.0    0.0    0.0   13.000000  180.0       2.0    1.0   \n",
       "614     3.0  1.0  35.0    0.0    0.0    8.050000  180.0       2.0    1.0   \n",
       "428     3.0  1.0  30.0    0.0    0.0    7.750000  180.0       1.0    1.0   \n",
       "325     1.0  0.0  36.0    0.0    0.0  135.633301   83.0       0.0    3.0   \n",
       "713     3.0  1.0  29.0    0.0    0.0    9.483300  180.0       2.0    1.0   \n",
       "161     2.0  0.0  40.0    0.0    0.0   15.750000  180.0       2.0    2.0   \n",
       "785     3.0  1.0  25.0    0.0    0.0    7.250000  180.0       2.0    1.0   \n",
       "486     1.0  0.0  35.0    1.0    0.0   90.000000  112.0       2.0    2.0   \n",
       "378     3.0  1.0  20.0    0.0    0.0    4.012500  180.0       0.0    1.0   \n",
       "\n",
       "     Honor  \n",
       "28     0.0  \n",
       "178    0.0  \n",
       "614    0.0  \n",
       "428    0.0  \n",
       "325    0.0  \n",
       "713    0.0  \n",
       "161    0.0  \n",
       "785    0.0  \n",
       "486    0.0  \n",
       "378    0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(batch, X, y):\n",
    "    num = np.arange(len(X))\n",
    "    np.random.shuffle(num)\n",
    "    select = num[0:batch]\n",
    "    x_batch = X.iloc[select]\n",
    "    y_batch = y[select]\n",
    "    \n",
    "    return(x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    total_loss = 0\n",
    "    for i in range(num_iterations):\n",
    "        x_batch, y_batch = next_batch(batch_size, X_train_data, y_train_data)\n",
    "        feed_dict_train = {X_place: x_batch, y_place: y_batch}\n",
    "        _, loss = sess.run([train_op, cost], feed_dict=feed_dict_train)\n",
    "        total_loss += loss\n",
    "        print('Epoch: {:04d}, total loss={:.9f}'.format(epoch+1, total_loss))\n",
    "    print ('Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow variables\n",
    "features= len(sFeatures)\n",
    "X_place = tf.placeholder(tf.float32, shape=[None,features])\n",
    "y_place = tf.placeholder(tf.float32, shape=[None,2])\n",
    "W = tf.Variable(tf.random_normal([features, 2]), name='weights')\n",
    "b = tf.Variable(tf.zeros(2), name='bias')\n",
    "logits = tf.matmul(X_place, W) + b\n",
    "y_pred = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Entropy\n",
    "learning_rate = 0.001\n",
    "cross_entropy = -tf.reduce_sum(y_place * tf.log(y_pred + 1e-10), axis=1)\n",
    "# cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y_train)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.Session()\n",
    "# sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training starting option 1\n",
    "# for epoch in range(10000):\n",
    "#     total_loss = 0.\n",
    "#     x_batch, y_batch = next_batch(batch_size, X_train, y_train)\n",
    "#     feed_dict_train = {X_place: x_batch, y_place: y_batch}\n",
    "#     _, loss = sess.run([train_op, cost], feed_dict=feed_dict_train)\n",
    "#     total_loss += loss\n",
    "#     print('Epoch: {:04d}, total loss={:.9f}'.format(epoch+1, total_loss))\n",
    "# #     print('Epoch: {:04d}, total loss={:.9f}, entropy: {}'.format(epoch+1, total_loss, cross_entropy))\n",
    "# #     print('predict: {:.6f}'.format(y_pred))\n",
    "# print ('Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training starting option 1 with CPU\n",
    "# for epoch in range(100):\n",
    "#     total_loss = 0.\n",
    "#     for i in range(len(X_train)):\n",
    "#         feed = {X_place: X_train, y_place: y_train}\n",
    "#         _, loss = sess.run([train_op, cost], feed_dict=feed)\n",
    "#         total_loss += loss\n",
    "#     print('Epoch: {:04d}, total loss={:.9f}'.format(epoch+1, total_loss))\n",
    "# #     print('Epoch: {:04d}, total loss={:.9f}, entropy: {}'.format(epoch+1, total_loss, cross_entropy))\n",
    "# #     print('predict: {:.6f}'.format(y_pred))\n",
    "# print ('Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training starting option 1 with GPU\n",
    "# with tf.device('/device:GPU:0'):\n",
    "start = time.time()\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        \n",
    "\n",
    "end = time.time()\n",
    "print('time spend: {:.4f} sec'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = saver.save(sess, model_path+'Titanic_model.ckpt')\n",
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the training data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path+'Titanic_model.ckpt')\n",
    "    feed_dict_train = {X_place: X_train_data}\n",
    "    prediction = sess.run(y_pred, feed_dict=feed_dict_train)\n",
    "    correct = np.equal(np.argmax(prediction,axis=1), np.argmax(y_train_data,axis=1))\n",
    "# evaluate the accuracy\n",
    "accuracy = np.mean(correct)\n",
    "print('Accuracy on validation: {:2.2%}'.format (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the validate data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path+'Titanic_model.ckpt')\n",
    "    feed_dict_valid = {X_place: X_val_data}\n",
    "    prediction = sess.run(y_pred, feed_dict=feed_dict_valid)\n",
    "    correct = np.equal(np.argmax(prediction,axis=1), np.argmax(y_val_data,axis=1))\n",
    "# evaluate the accuracy\n",
    "\n",
    "accuracy = np.mean(correct)\n",
    "print('Accuracy on validation: {:2.2%}'.format (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction for test data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path+'Titanic_model.ckpt')\n",
    "    feed_dict_test = {X_place: X_test}\n",
    "    prediction = sess.run(y_pred, feed_dict=feed_dict_test)\n",
    "    y_predict = np.argmax(prediction, axis=1)\n",
    "# evaluate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengerid = np.array(df_test.PassengerId.tolist())\n",
    "submission = pd.DataFrame({'PassengerId': passengerid, 'Survived': y_predict}).set_index('PassengerId')\n",
    "submission.to_csv('submission_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_accuracy()\n",
    "# plot_example_errors()\n",
    "# optimize(num_iterations=10)\n",
    "print_accuracy()\n",
    "# plot_example_errors()\n",
    "# plot_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "File_Writer=tf.summary.FileWriter(''/Users/lambert/Documents/Python_code/tensorflow_code/Titanic'\n",
    "                                  ,sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate as much GPU memory based on runtime allocations\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate 40% memory of GPU\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = tf.Session(config=config, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically choose existing in case specified one doesn't exit\n",
    "# allow_soft_placement=True\n",
    "with tf.device('/device:GPU:2'):\n",
    "  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "  c = tf.matmul(a, b)\n",
    "# Creates a session with allow_soft_placement and log_device_placement set\n",
    "# to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(C=1, max_iter=100, solver='lbfgs').fit(X_train, y_train)\n",
    "yp = lr.predict(X_train)\n",
    "y_predict = lr.predict(X_test)\n",
    "\n",
    "passengerid = np.array(df_test.PassengerId.tolist())\n",
    "submission = pd.DataFrame({'PassengerId': passengerid, 'Survived': y_predict}).set_index('PassengerId')\n",
    "submission.to_csv('submission_knn.csv')\n",
    "# passengerid = np.array(df_train.PassengerId.tolist())\n",
    "# submission = pd.DataFrame({'PassengerId': passengerid, 'Survived': yp}).set_index('PassengerId')\n",
    "# submission.to_csv('y_train_predict.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting Classifier\n",
    "# gbdt = GradientBoostingClassifier(n_estimators=300, max_depth=5).fit(X_train, y_train)\n",
    "# y_predict = gbdt.predict(X_test)\n",
    "\n",
    "# passengerid = np.array(df_test.PassengerId.tolist())\n",
    "# submission = pd.DataFrame({'PassengerId': passengerid, 'Survived': y_predict}).set_index('PassengerId')\n",
    "# submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "rfc = RandomForestClassifier(n_estimators=200, max_depth=3).fit(X_train, y_train)\n",
    "y_predict = rfc.predict(X_test)\n",
    "passengerid = np.array(df_test.PassengerId.tolist())\n",
    "submission = pd.DataFrame({'PassengerId': passengerid, 'Survived': y_predict}).set_index('PassengerId')\n",
    "submission.to_csv('submission_random.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent (SDG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent (SGD) easily scale with more than 10^5 samples and features\n",
    "sgd = SGDClassifier(alpha=0.01, max_iter=1000).fit(X_train, y_train)\n",
    "y_predict = sgd.predict(X_test)\n",
    "passengerid = np.array(df_test.PassengerId.tolist())\n",
    "submission = pd.DataFrame({'PassengerId': passengerid, 'Survived': y_predict}).set_index('PassengerId')\n",
    "submission.to_csv('submission_sdg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
