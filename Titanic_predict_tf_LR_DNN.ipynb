{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import sys\n",
    "import re\n",
    "import time\n",
    "import shutil\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.client import device_lib\n",
    "model_path = '/home/lambert/Git/Titanic/Titanic_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    if pd.isnull(name):\n",
    "        return 'Null'\n",
    "    title_search = re.search('([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1).lower()\n",
    "    else:\n",
    "        return 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = {'mr':1, 'mrs':2, 'mme':2, 'ms':3, 'miss':3, 'mlle':3, 'don':4, 'sir':4, 'jonkheer':4,\n",
    "          'major':4, 'col':4, 'dr':4, 'master':4, 'capt':4, 'dona':5, 'lady':5, 'countess':5,\n",
    "         'rev':6}\n",
    "df_train['Title'] = df_train['Name'].apply(lambda name: titles.get(get_title(name)))\n",
    "df_train['Honor'] = df_train['Title'].apply(lambda title: 1 if title ==4 or title == 5 else 0)\n",
    "df_test['Title'] = df_test['Name'].apply(lambda name: titles.get(get_title(name)))\n",
    "df_test['Honor'] = df_test['Title'].apply(lambda title: 1 if title ==4 or title == 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lambert/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# 1. Data clearning\n",
    "# df_train.Age.fillna(fill_df_Age, inplace=True)\n",
    "# df_test.Age.fillna(fill_df_Age, inplace=True)\n",
    "for i in range(1,7):\n",
    "    a = df_train[(df_train.Age.isnull()) & (df_train.Title==i)]\n",
    "    df_train.Age.iloc[a.index] = df_train.Age[df_train.Title==i].median()\n",
    "    b = df_test[(df_test.Age.isnull()) & (df_test.Title==i)]\n",
    "    df_test.Age.iloc[b.index] = df_train.Age[df_train.Title==i].median()\n",
    "\n",
    "# Cabin - fill nan with 'fill' and select first cabin\n",
    "df_train.Cabin.fillna('fill',inplace=True)\n",
    "df_train.Cabin = df_train.Cabin.map(lambda x:x.split(' ')[0])\n",
    "df_test.Cabin.fillna('fill', inplace=True)\n",
    "df_test.Cabin = df_test.Cabin.map(lambda x:x.split(' ')[0])\n",
    "\n",
    "# Sex - male: 1, female: 1\n",
    "df_train.Sex.replace({'male':1, 'female':0}, inplace=True)\n",
    "df_test.Sex.replace({'male':1, 'female':0}, inplace=True)\n",
    "\n",
    "df_train = df_train.dropna(axis=0, how='any')\n",
    "df_test.Fare.fillna(df_test.Fare.mean(), inplace=True)\n",
    "\n",
    "# Create a 'Deceased' column for sconed class\n",
    "df_train['Deceased'] = df_train.Survived.apply(lambda s: int(not s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Select the features\n",
    "sFeatures = ['Pclass',\n",
    " 'Sex',\n",
    " 'Age',\n",
    " 'SibSp',\n",
    " 'Parch',\n",
    " 'Fare',             \n",
    " 'Cabin',             \n",
    " 'Embarked',\n",
    " 'Title',\n",
    " 'Honor']\n",
    "LABEL = ['Survived', 'Deceased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Label Encoder\n",
    "# X_test has elements that X doesn't have\n",
    "# create a Cabin_labels cover X and X_test\n",
    "X_Cabin_unique = df_train['Cabin'].unique()\n",
    "X_lack = df_test.Cabin[df_test['Cabin'].isin(X_Cabin_unique)==0].values\n",
    "Cabin_labels = np.append(X_Cabin_unique, X_lack)\n",
    "# print(X_Cabin_unique.shape, X_Cabin_unique)\n",
    "# print(Cabin_labels.shape, Cabin_labels)\n",
    "\n",
    "le_Cabin = LabelEncoder().fit(Cabin_labels)\n",
    "le_Embarked = LabelEncoder().fit(np.array(df_train['Embarked'].tolist()))\n",
    "\n",
    "df_train.loc[:,'Cabin'] = le_Cabin.transform(df_train['Cabin'])\n",
    "df_train.loc[:,'Embarked'] = le_Embarked.transform(df_train['Embarked'])\n",
    "df_test.loc[:,'Cabin'] = le_Cabin.transform(df_test['Cabin'])\n",
    "df_test.loc[:,'Embarked'] = le_Embarked.transform(df_test['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the feature engineer in DF, keep train and label index consistance\n",
    "# Split Validation with the selected features\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(df_train[sFeatures], df_train['Survived'])\n",
    "X_test = df_test[sFeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Validation\n",
    "# X_train = df_train[sFeatures]\n",
    "# y_train = df_train['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(X, y, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = X,\n",
    "    y = y,\n",
    "    batch_size = 10,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction_input_fn(X, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = X,\n",
    "    batch_size = 10,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_cols(X):\n",
    "  input_columns = [tf.feature_column.numeric_column(k) for k in X.columns]\n",
    "  return input_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Linear Regression with tf.Estimator framework </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'Titanic_trained_LR', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f40556a3748>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into Titanic_trained_LR/model.ckpt.\n",
      "INFO:tensorflow:loss = 4.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 598.236\n",
      "INFO:tensorflow:loss = 2.397627, step = 101 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 661.422\n",
      "INFO:tensorflow:loss = 1.7216803, step = 201 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 687.313\n",
      "INFO:tensorflow:loss = 1.9892299, step = 301 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 696.854\n",
      "INFO:tensorflow:loss = 0.5370657, step = 401 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 641.085\n",
      "INFO:tensorflow:loss = 0.87821794, step = 501 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.629\n",
      "INFO:tensorflow:loss = 1.6169083, step = 601 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.458\n",
      "INFO:tensorflow:loss = 1.8011632, step = 701 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 687.425\n",
      "INFO:tensorflow:loss = 0.7639744, step = 801 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.048\n",
      "INFO:tensorflow:loss = 1.2619112, step = 901 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 675.921\n",
      "INFO:tensorflow:loss = 0.9087085, step = 1001 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.345\n",
      "INFO:tensorflow:loss = 2.0669806, step = 1101 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 561.527\n",
      "INFO:tensorflow:loss = 1.2654824, step = 1201 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 571.927\n",
      "INFO:tensorflow:loss = 0.69188964, step = 1301 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 569.669\n",
      "INFO:tensorflow:loss = 0.96301246, step = 1401 (0.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 561.022\n",
      "INFO:tensorflow:loss = 2.2637565, step = 1501 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 634.67\n",
      "INFO:tensorflow:loss = 1.5624919, step = 1601 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 679.527\n",
      "INFO:tensorflow:loss = 1.0626705, step = 1701 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 574.598\n",
      "INFO:tensorflow:loss = 0.94009715, step = 1801 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 635.821\n",
      "INFO:tensorflow:loss = 1.6069882, step = 1901 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.008\n",
      "INFO:tensorflow:loss = 3.45779, step = 2001 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.123\n",
      "INFO:tensorflow:loss = 2.8658457, step = 2101 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 682.98\n",
      "INFO:tensorflow:loss = 1.5561414, step = 2201 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.427\n",
      "INFO:tensorflow:loss = 0.60200185, step = 2301 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 558.062\n",
      "INFO:tensorflow:loss = 1.3075279, step = 2401 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.919\n",
      "INFO:tensorflow:loss = 1.7201538, step = 2501 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.268\n",
      "INFO:tensorflow:loss = 1.1678791, step = 2601 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 679.757\n",
      "INFO:tensorflow:loss = 1.7496771, step = 2701 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 696.514\n",
      "INFO:tensorflow:loss = 0.43289828, step = 2801 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 693.594\n",
      "INFO:tensorflow:loss = 0.9706451, step = 2901 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 689.729\n",
      "INFO:tensorflow:loss = 3.1624668, step = 3001 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.803\n",
      "INFO:tensorflow:loss = 1.3193574, step = 3101 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 665.017\n",
      "INFO:tensorflow:loss = 1.0702231, step = 3201 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 652.46\n",
      "INFO:tensorflow:loss = 0.93752235, step = 3301 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.438\n",
      "INFO:tensorflow:loss = 1.6654804, step = 3401 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.019\n",
      "INFO:tensorflow:loss = 2.2436357, step = 3501 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 681.27\n",
      "INFO:tensorflow:loss = 1.5553606, step = 3601 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 693.56\n",
      "INFO:tensorflow:loss = 1.6757247, step = 3701 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 684.865\n",
      "INFO:tensorflow:loss = 1.5764151, step = 3801 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 697.679\n",
      "INFO:tensorflow:loss = 0.42316005, step = 3901 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 713.095\n",
      "INFO:tensorflow:loss = 2.5354981, step = 4001 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 675.446\n",
      "INFO:tensorflow:loss = 1.9530445, step = 4101 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 665.557\n",
      "INFO:tensorflow:loss = 0.59476227, step = 4201 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.17\n",
      "INFO:tensorflow:loss = 1.024379, step = 4301 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.929\n",
      "INFO:tensorflow:loss = 1.1228331, step = 4401 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 630.622\n",
      "INFO:tensorflow:loss = 2.4946985, step = 4501 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 684.738\n",
      "INFO:tensorflow:loss = 0.88213503, step = 4601 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 652.068\n",
      "INFO:tensorflow:loss = 0.6816919, step = 4701 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 630.85\n",
      "INFO:tensorflow:loss = 1.1661605, step = 4801 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.257\n",
      "INFO:tensorflow:loss = 1.0736675, step = 4901 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 681.302\n",
      "INFO:tensorflow:loss = 1.5974655, step = 5001 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.433\n",
      "INFO:tensorflow:loss = 2.7397861, step = 5101 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 702.113\n",
      "INFO:tensorflow:loss = 0.30181664, step = 5201 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 705.317\n",
      "INFO:tensorflow:loss = 1.1259706, step = 5301 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 718.277\n",
      "INFO:tensorflow:loss = 1.1312795, step = 5401 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 684.061\n",
      "INFO:tensorflow:loss = 2.022446, step = 5501 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.696\n",
      "INFO:tensorflow:loss = 2.3091605, step = 5601 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 696.641\n",
      "INFO:tensorflow:loss = 2.2742832, step = 5701 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.98\n",
      "INFO:tensorflow:loss = 1.7182581, step = 5801 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 635.364\n",
      "INFO:tensorflow:loss = 0.82288545, step = 5901 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 672.453\n",
      "INFO:tensorflow:loss = 1.4413896, step = 6001 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 663.999\n",
      "INFO:tensorflow:loss = 2.1864314, step = 6101 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 677.839\n",
      "INFO:tensorflow:loss = 1.8659747, step = 6201 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 697.46\n",
      "INFO:tensorflow:loss = 1.5128798, step = 6301 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 697.759\n",
      "INFO:tensorflow:loss = 1.9541029, step = 6401 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.378\n",
      "INFO:tensorflow:loss = 1.0282075, step = 6501 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 751.623\n",
      "INFO:tensorflow:loss = 1.3591988, step = 6601 (0.133 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6660 into Titanic_trained_LR/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.3371252.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x7f40556a3128>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "OUTDIR_LR = 'Titanic_trained_LR'\n",
    "shutil.rmtree(OUTDIR_LR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "model_LR = tf.estimator.LinearRegressor(\n",
    "      feature_columns = make_feature_cols(X_train), model_dir = OUTDIR_LR)\n",
    "\n",
    "model_LR.train(input_fn = make_input_fn(X_train, y_train, num_epochs = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step :  6660\n",
      "linear/linear_model/Age/weights :  [[-0.00011609]]\n",
      "linear/linear_model/Age/weights/part_0/Ftrl :  [[1.1253554e+09]]\n",
      "linear/linear_model/Age/weights/part_0/Ftrl_1 :  [[19.47216]]\n",
      "linear/linear_model/Cabin/weights :  [[0.00151247]]\n",
      "linear/linear_model/Cabin/weights/part_0/Ftrl :  [[2.759205e+10]]\n",
      "linear/linear_model/Cabin/weights/part_0/Ftrl_1 :  [[-1256.171]]\n",
      "linear/linear_model/Embarked/weights :  [[0.00034723]]\n",
      "linear/linear_model/Embarked/weights/part_0/Ftrl :  [[2971344.8]]\n",
      "linear/linear_model/Embarked/weights/part_0/Ftrl_1 :  [[-2.9926672]]\n",
      "linear/linear_model/Fare/weights :  [[0.00083413]]\n",
      "linear/linear_model/Fare/weights/part_0/Ftrl :  [[1.3500308e+09]]\n",
      "linear/linear_model/Fare/weights/part_0/Ftrl_1 :  [[-153.24123]]\n",
      "linear/linear_model/Honor/weights :  [[0.1443985]]\n",
      "linear/linear_model/Honor/weights/part_0/Ftrl :  [[3921.3982]]\n",
      "linear/linear_model/Honor/weights/part_0/Ftrl_1 :  [[-45.211937]]\n",
      "linear/linear_model/Parch/weights :  [[-0.02296727]]\n",
      "linear/linear_model/Parch/weights/part_0/Ftrl :  [[61908.273]]\n",
      "linear/linear_model/Parch/weights/part_0/Ftrl_1 :  [[28.572855]]\n",
      "linear/linear_model/Pclass/weights :  [[-0.09309094]]\n",
      "linear/linear_model/Pclass/weights/part_0/Ftrl :  [[3436199.8]]\n",
      "linear/linear_model/Pclass/weights/part_0/Ftrl_1 :  [[862.81287]]\n",
      "linear/linear_model/Sex/weights :  [[-0.3416335]]\n",
      "linear/linear_model/Sex/weights/part_0/Ftrl :  [[535711.25]]\n",
      "linear/linear_model/Sex/weights/part_0/Ftrl_1 :  [[1250.247]]\n",
      "linear/linear_model/SibSp/weights :  [[-0.06943396]]\n",
      "linear/linear_model/SibSp/weights/part_0/Ftrl :  [[186719.19]]\n",
      "linear/linear_model/SibSp/weights/part_0/Ftrl_1 :  [[150.01561]]\n",
      "linear/linear_model/Title/weights :  [[0.12327746]]\n",
      "linear/linear_model/Title/weights/part_0/Ftrl :  [[2480327.2]]\n",
      "linear/linear_model/Title/weights/part_0/Ftrl_1 :  [[-970.7517]]\n",
      "linear/linear_model/bias_weights :  [0.38164508]\n",
      "linear/linear_model/bias_weights/part_0/Ftrl :  [986054.1]\n",
      "linear/linear_model/bias_weights/part_0/Ftrl_1 :  [-1894.8727]\n"
     ]
    }
   ],
   "source": [
    "# Get all weights\n",
    "for i,name in enumerate(model_LR.get_variable_names()):\n",
    "    print(name,\": \", model_LR.get_variable_value(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Validate the model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rmse(model, name, X, y):\n",
    "  metrics = model.evaluate(input_fn = make_input_fn(X, y, 1))\n",
    "  print('RMSE on {} dataset = {}'.format(name, np.sqrt(metrics['average_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-05-29-09:14:18\n",
      "INFO:tensorflow:Restoring parameters from Titanic_trained_LR/model.ckpt-6660\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-29-09:14:18\n",
      "INFO:tensorflow:Saving dict for global step 6660: average_loss = 0.154401, global_step = 6660, loss = 1.4970185\n",
      "RMSE on validation dataset = 0.3929389417171478\n"
     ]
    }
   ],
   "source": [
    "print_rmse(model_LR, 'validation', X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Prediction X_test </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Titanic_trained_LR/model.ckpt-6660\n",
      "[0.5362988, 0.13326523, 0.7433491, 0.7494205, 0.38045114, 0.5371604, 0.54717654, 0.19893295, 0.16018727, 0.25578195, 0.68654585, 0.25787157, 0.16016197, 0.74927354, 0.52658844, 0.62288415, 0.94566065, 0.24879676, 0.6796294, 0.38999915, 0.18320772, 0.74882305, 0.2941957, 0.16302487, 0.7493733, 0.31617105, 0.15958986, 0.37218788, 0.1982119, 0.53401715, 0.5850151, -0.06465304, 0.25754476, 0.1600587, 0.16040698, 0.7344755, 0.75006557, 0.25740722, 0.12420851, 0.6559217, -0.0012636185, 0.60826427, 0.09381163, 0.8230898, 0.16209128, 0.09679389, 0.94285303, 0.5027359, 0.3026828, 0.7488474, 0.5928194, 0.23326151, 0.27570915, 0.09644565, 0.55897635, 0.15853322, 0.13466728, 0.17249358, 0.749025, 0.70065594, 0.28466463, 0.5636561, 0.15814784, 0.3614523, 0.70639634, 0.15975219, 0.6638439, 0.6406336, 0.25845203, 0.74847484, 0.16066355, 0.62989795, 0.35569003, 0.16065446, 0.15880468, 0.15935317, 0.15915295, 0.22955053, 0.1598495, 0.16088381, 0.09649411, 0.16069373, 0.51982903, 0.21320926, 0.15958986, 0.74882305, 0.1594598, 0.18589528, 0.09540081, 0.15986934, 0.161116, 0.159839, 0.26848304, 0.16484895, 0.16104648, 0.27341908, 0.25671068, 0.16055578, 0.6757091, 0.25291896, 0.1607205, 0.8240914, 0.74452305, 0.39967746, 0.16197723, 0.86656713, 0.16046682, 0.74882305, 0.5819149, 0.2565989, 0.73817116, 0.15956241, 0.74993145, 0.7404553, 1.2309347, 0.8445213, 0.68955815, 0.25601843, 0.7299199, 0.15958986, 0.25334832, 0.74696565, 0.19498584, 0.14207631, 0.25886413, 0.7135992, 0.19652528, 0.25874862, 0.63835025, 0.58389103, 0.74868613, 0.3562789, 0.25852075, 0.7223182, 0.19649503, 0.6638844, 0.2571422, 0.33965442, 0.09015584, 0.87251747, 0.2561345, 0.25514838, 0.6602451, 0.7570635, 0.52199495, 0.84647703, 1.0059484, 0.13699518, 0.6498189, 0.3613418, 0.36180058, 0.69410455, 0.5448184, 0.16104648, 0.15931144, 0.22156596, 0.088713884, 0.5528149, 0.7091968, 0.5901109, 0.61094743, 1.0539069, 0.2924239, 0.6307805, 0.7336324, 0.7483876, 0.7489308, 0.15958986, 0.111828834, 0.73672575, 0.15977028, 0.11848462, 0.84687257, 0.74882305, -0.03993106, 0.20059744, 0.2560141, 0.16018727, 0.25590235, 1.1442618, 0.2750681, 0.09779787, 0.7742984, 0.6932626, 0.090501726, 0.21450551, 0.16018727, 0.15880468, 0.7881662, 0.1885628, 0.15979114, 0.8304129, 0.19931331, 0.15958986, 0.19835249, 0.25590235, 0.76739484, 0.6858536, 0.36040747, 0.7552876, 0.5745654, 0.15995508, 0.9546572, 0.1588082, 0.16019917, 0.35948434, 0.37760735, 0.16037223, 0.62511224, 0.25427276, 0.74711096, 0.022828579, 0.1588082, 0.17964947, 0.15977028, 0.16018727, 0.6372248, 0.6638439, 0.3612278, 0.19765595, 0.16118488, 0.6499416, 0.15958986, 0.68882245, 0.74969923, 0.5614727, 0.83034617, 0.703, 0.16016579, 0.2572008, 0.8844213, 0.684841, 0.16018727, 0.59006715, 0.590188, 0.62279046, 0.30938125, 0.15973341, 0.23960379, 0.14880139, 0.16133013, 0.19916514, -0.0057774186, 0.13995722, 0.15967536, 0.5019802, 0.13489947, 0.71949625, 0.5959276, 1.0131285, 0.30926514, 0.15854952, 0.1619474, 0.3932689, 0.6693702, 0.5899948, 0.6469177, 0.16041946, 0.25625062, 0.16088665, 0.77569425, 0.27130392, 0.17274275, 0.4235472, 0.1720292, 0.03579372, 0.15882346, 0.3191961, 0.74966735, 0.09540427, 0.72887504, 0.2724648, 0.33935785, -0.059308797, 0.16042227, 0.5760244, 0.3604319, 0.6637202, 0.25875703, 0.74953943, 0.09746814, 0.8287096, 0.6651653, 0.16139475, 0.16110352, 0.25671497, 0.7922369, 0.250582, 0.16004482, 0.67919075, 0.7545874, 0.7946172, 0.76759374, 0.15958986, 0.25649378, 0.38163903, 0.7483785, 0.16014004, 0.67918575, 0.16070023, 0.25740722, 0.25717503, 0.37268597, 0.13625407, 0.03199351, 0.69726896, 0.19464621, 0.22599272, 0.15969762, 1.103081, 0.16106877, 0.25574866, 0.5844035, 0.16073993, 0.4031656, 0.1622074, 0.18750696, 0.95103383, 0.15947825, 0.15967569, 0.16014326, 0.7471978, 0.7494205, 0.15977028, 0.1964264, 0.36823574, 0.7284107, 0.12779236, 0.78622067, 0.8499791, 0.18776682, 0.16052306, 0.6698698, 0.15913355, 0.2562463, 0.32084537, 0.74847484, 0.45679978, 0.7482343, 0.65339017, 0.37304798, 0.7488091, 0.717124, 0.16102013, 0.15958986, 0.15952, 0.2573029, 0.8240942, 0.25787157, 0.25593734, 0.15972573, 0.9993064, 0.16063467, 0.25759202, 0.1615679, 0.7491883, 0.16123208, 0.74882305, 0.62456995, 0.16018727, 0.161244, 0.16100273, 0.766592, -0.015805185, 0.16162111, 0.16063917, 0.5396955, 0.6635314, 0.8521525, 0.17881638, 0.16005173, 0.10216108, 0.74872404, 0.66278887, 0.5895448, 0.248155, 0.5619203, 0.17987835, 0.3026394, 0.15921101, 0.8264132, 0.12611037, 0.77176476, 0.16090405, 0.1587435, 0.18670052, 0.55973136, 0.16042227, 0.7497688, 0.25555408, 0.3731166, 0.5606724, 0.35913607, 0.7476775, 0.73035157, 0.6908287, 0.14822093, 0.15958986, 0.6879914, 0.7487987, 0.74927914, 0.03199351, 0.9426646, 0.16110653, 0.7459065, 0.75673807, 0.16078794, 0.14984685, 0.6219743, 0.7761831, 0.19371748, 0.15995792, 0.1599656, 0.1600587, 0.74009514, 0.15936425, 0.1600587, 0.52377474]\n"
     ]
    }
   ],
   "source": [
    "preds_iter = model_LR.predict(input_fn = make_prediction_input_fn(X_test,1))\n",
    "# print([pred['predictions'][0] for pred in list(itertools.islice(preds_iter, 5))])\n",
    "print([pred['predictions'][0] for pred in list(itertools.islice(preds_iter, 0, len(X_test)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=itertools.islice(np.arange(100),0,100,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-29-04:15:53\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from Titanic_trained_LR/model.ckpt-6660\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-29-04:15:53\n",
      "INFO:tensorflow:Saving dict for global step 6660: average_loss = 0.16010863, global_step = 6660, loss = 1.5523576\n",
      "RMSE on validation dataset = 0.40013575553894043\n"
     ]
    }
   ],
   "source": [
    "feed_dict_train = {X_place: X_train}\n",
    "        prediction = sess.run(y_pred, feed_dict=feed_dict_train)\n",
    "        correct = np.equal(np.argmax(prediction,axis=1), np.argmax(y_train,axis=1))\n",
    "        # evaluate the accuracy\n",
    "        accuracy = np.mean(correct)\n",
    "        print('Accuracy on validation: {:2.2%}'.format (accuracy))\n",
    "    save_path = saver.save(sess, model_path+'Titanic_model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Deep Neural Network regression </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'Titanic_trained_DNN', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1170558d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into Titanic_trained_DNN/model.ckpt.\n",
      "INFO:tensorflow:loss = 5.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 297.618\n",
      "INFO:tensorflow:loss = 1.5687172, step = 101 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.122\n",
      "INFO:tensorflow:loss = 2.6633174, step = 201 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.869\n",
      "INFO:tensorflow:loss = 2.1627471, step = 301 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.608\n",
      "INFO:tensorflow:loss = 2.2055483, step = 401 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.379\n",
      "INFO:tensorflow:loss = 2.8613296, step = 501 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.68\n",
      "INFO:tensorflow:loss = 2.4037654, step = 601 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.37\n",
      "INFO:tensorflow:loss = 2.162193, step = 701 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.167\n",
      "INFO:tensorflow:loss = 2.173275, step = 801 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.579\n",
      "INFO:tensorflow:loss = 2.1645198, step = 901 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.291\n",
      "INFO:tensorflow:loss = 2.637846, step = 1001 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.689\n",
      "INFO:tensorflow:loss = 2.168597, step = 1101 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.731\n",
      "INFO:tensorflow:loss = 2.6529307, step = 1201 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.592\n",
      "INFO:tensorflow:loss = 2.1629648, step = 1301 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.96\n",
      "INFO:tensorflow:loss = 1.9456266, step = 1401 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.369\n",
      "INFO:tensorflow:loss = 2.1736155, step = 1501 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.035\n",
      "INFO:tensorflow:loss = 2.1731467, step = 1601 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.913\n",
      "INFO:tensorflow:loss = 2.164084, step = 1701 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.797\n",
      "INFO:tensorflow:loss = 2.6461692, step = 1801 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.148\n",
      "INFO:tensorflow:loss = 2.4015305, step = 1901 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.206\n",
      "INFO:tensorflow:loss = 3.3675847, step = 2001 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.856\n",
      "INFO:tensorflow:loss = 1.9351486, step = 2101 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.066\n",
      "INFO:tensorflow:loss = 1.9370672, step = 2201 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.844\n",
      "INFO:tensorflow:loss = 2.401974, step = 2301 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.062\n",
      "INFO:tensorflow:loss = 2.9057565, step = 2401 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.342\n",
      "INFO:tensorflow:loss = 2.4014683, step = 2501 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.611\n",
      "INFO:tensorflow:loss = 2.4044366, step = 2601 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.757\n",
      "INFO:tensorflow:loss = 1.6718287, step = 2701 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.027\n",
      "INFO:tensorflow:loss = 2.163066, step = 2801 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.838\n",
      "INFO:tensorflow:loss = 2.6353135, step = 2901 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.547\n",
      "INFO:tensorflow:loss = 2.6205924, step = 3001 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.041\n",
      "INFO:tensorflow:loss = 2.1619573, step = 3101 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.408\n",
      "INFO:tensorflow:loss = 2.4065962, step = 3201 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.556\n",
      "INFO:tensorflow:loss = 2.6240048, step = 3301 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.059\n",
      "INFO:tensorflow:loss = 3.1291785, step = 3401 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.191\n",
      "INFO:tensorflow:loss = 1.9395778, step = 3501 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.195\n",
      "INFO:tensorflow:loss = 1.9468167, step = 3601 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.045\n",
      "INFO:tensorflow:loss = 2.154723, step = 3701 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.546\n",
      "INFO:tensorflow:loss = 2.6423738, step = 3801 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 529.558\n",
      "INFO:tensorflow:loss = 2.170783, step = 3901 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.153\n",
      "INFO:tensorflow:loss = 2.4031315, step = 4001 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.768\n",
      "INFO:tensorflow:loss = 2.1652036, step = 4101 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.175\n",
      "INFO:tensorflow:loss = 1.9193547, step = 4201 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.204\n",
      "INFO:tensorflow:loss = 2.1690228, step = 4301 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.208\n",
      "INFO:tensorflow:loss = 2.6489854, step = 4401 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.741\n",
      "INFO:tensorflow:loss = 2.894692, step = 4501 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.288\n",
      "INFO:tensorflow:loss = 2.6358283, step = 4601 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.319\n",
      "INFO:tensorflow:loss = 2.40106, step = 4701 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.485\n",
      "INFO:tensorflow:loss = 1.9416796, step = 4801 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.959\n",
      "INFO:tensorflow:loss = 2.4058728, step = 4901 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.516\n",
      "INFO:tensorflow:loss = 1.9340239, step = 5001 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.986\n",
      "INFO:tensorflow:loss = 2.1642857, step = 5101 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.798\n",
      "INFO:tensorflow:loss = 2.6286056, step = 5201 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.975\n",
      "INFO:tensorflow:loss = 2.646499, step = 5301 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.093\n",
      "INFO:tensorflow:loss = 1.9440317, step = 5401 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.156\n",
      "INFO:tensorflow:loss = 2.4037185, step = 5501 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.223\n",
      "INFO:tensorflow:loss = 1.396216, step = 5601 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.798\n",
      "INFO:tensorflow:loss = 2.4035666, step = 5701 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.206\n",
      "INFO:tensorflow:loss = 2.173207, step = 5801 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.323\n",
      "INFO:tensorflow:loss = 2.6275988, step = 5901 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.496\n",
      "INFO:tensorflow:loss = 2.40549, step = 6001 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.08\n",
      "INFO:tensorflow:loss = 3.1444812, step = 6101 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.93\n",
      "INFO:tensorflow:loss = 2.1679606, step = 6201 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 511.052\n",
      "INFO:tensorflow:loss = 2.403995, step = 6301 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 532.232\n",
      "INFO:tensorflow:loss = 2.1664987, step = 6401 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.463\n",
      "INFO:tensorflow:loss = 2.4028192, step = 6501 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.427\n",
      "INFO:tensorflow:loss = 1.9589474, step = 6601 (0.504 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6660 into Titanic_trained_DNN/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.1643336.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x117398d68>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTDIR_DNN = 'Titanic_trained_DNN'\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "shutil.rmtree(OUTDIR_DNN, ignore_errors = True) # start fresh each time\n",
    "model_DNN = tf.estimator.DNNRegressor(hidden_units = [32, 8, 2],\n",
    "      feature_columns = make_feature_cols(X_train), model_dir = OUTDIR_DNN)\n",
    "model_DNN.train(input_fn = make_input_fn(X_train, y_train, num_epochs = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-29-04:24:21\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from Titanic_trained_DNN/model.ckpt-6660\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-29-04:24:22\n",
      "INFO:tensorflow:Saving dict for global step 6660: average_loss = 0.23695736, global_step = 6660, loss = 2.2974563\n",
      "RMSE on validation dataset = 0.48678267002105713\n"
     ]
    }
   ],
   "source": [
    "print_rmse(model_DNN, 'validation', X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_iter = model_LR.predict(input_fn = make_prediction_input_fn(X_test,1))\n",
    "# print([pred['predictions'][0] for pred in list(itertools.islice(preds_iter, 5))])\n",
    "print([pred['predictions'][0] for pred in list(itertools.islice(preds_iter, 0, len(X_test)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow variables\n",
    "# with tf.device('/device:GPU:0'):\n",
    "features= len(sFeatures)\n",
    "X_place = tf.placeholder(tf.float32, shape=[None,features])\n",
    "y_place = tf.placeholder(tf.float32, shape=[None,2])\n",
    "W = tf.Variable(tf.random_normal([features, 2]), name='weights')\n",
    "b = tf.Variable(tf.zeros(2), name='bias')\n",
    "logits = tf.matmul(X_place, W) + b\n",
    "y_pred = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Entropy\n",
    "# with tf.device('/device:GPU:0'):\n",
    "learning_rate = 0.001\n",
    "cross_entropy = -tf.reduce_sum(y_place * tf.log(y_pred + 1e-10), axis=1)\n",
    "# cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y_train)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.Session()\n",
    "# sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training starting option 1\n",
    "# for epoch in range(10000):\n",
    "#     total_loss = 0.\n",
    "#     x_batch, y_batch = next_batch(batch_size, X_train, y_train)\n",
    "#     feed_dict_train = {X_place: x_batch, y_place: y_batch}\n",
    "#     _, loss = sess.run([train_op, cost], feed_dict=feed_dict_train)\n",
    "#     total_loss += loss\n",
    "#     print('Epoch: {:04d}, total loss={:.9f}'.format(epoch+1, total_loss))\n",
    "# #     print('Epoch: {:04d}, total loss={:.9f}, entropy: {}'.format(epoch+1, total_loss, cross_entropy))\n",
    "# #     print('predict: {:.6f}'.format(y_pred))\n",
    "# print ('Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training starting option 1 with CPU\n",
    "# for epoch in range(100):\n",
    "#     total_loss = 0.\n",
    "#     for i in range(len(X_train)):\n",
    "#         feed = {X_place: X_train, y_place: y_train}\n",
    "#         _, loss = sess.run([train_op, cost], feed_dict=feed)\n",
    "#         total_loss += loss\n",
    "#     print('Epoch: {:04d}, total loss={:.9f}'.format(epoch+1, total_loss))\n",
    "# #     print('Epoch: {:04d}, total loss={:.9f}, entropy: {}'.format(epoch+1, total_loss, cross_entropy))\n",
    "# #     print('predict: {:.6f}'.format(y_pred))\n",
    "# print ('Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001, total loss=7741.516098022\n",
      "Epoch: 0002, total loss=7738.829321861\n",
      "Epoch: 0003, total loss=7734.809428215\n",
      "Epoch: 0004, total loss=7731.230428696\n",
      "Epoch: 0005, total loss=7730.431954384\n",
      "Epoch: 0006, total loss=7730.153929710\n",
      "Epoch: 0007, total loss=7729.909674644\n",
      "Epoch: 0008, total loss=7729.665932655\n",
      "Epoch: 0009, total loss=7729.419364929\n",
      "Epoch: 0010, total loss=7729.170191765\n",
      "Epoch: 0011, total loss=7728.918432236\n",
      "Epoch: 0012, total loss=7728.664295197\n",
      "Epoch: 0013, total loss=7728.407405853\n",
      "Epoch: 0014, total loss=7728.149026871\n",
      "Epoch: 0015, total loss=7727.888969421\n",
      "Epoch: 0016, total loss=7727.626473427\n",
      "Epoch: 0017, total loss=7727.363004684\n",
      "Epoch: 0018, total loss=7727.097887993\n",
      "Epoch: 0019, total loss=7726.830873489\n",
      "Epoch: 0020, total loss=7726.563403130\n",
      "Epoch: 0021, total loss=7726.293632507\n",
      "Epoch: 0022, total loss=7726.022218704\n",
      "Epoch: 0023, total loss=7725.749572754\n",
      "Epoch: 0024, total loss=7725.473988533\n",
      "Epoch: 0025, total loss=7725.196638107\n",
      "Epoch: 0026, total loss=7724.916168213\n",
      "Epoch: 0027, total loss=7724.632925987\n",
      "Epoch: 0028, total loss=7724.346180916\n",
      "Epoch: 0029, total loss=7724.055155754\n",
      "Epoch: 0030, total loss=7723.758786201\n",
      "Epoch: 0031, total loss=7723.456103325\n",
      "Epoch: 0032, total loss=7723.145912170\n",
      "Epoch: 0033, total loss=7722.826562881\n",
      "Epoch: 0034, total loss=7722.495479584\n",
      "Epoch: 0035, total loss=7722.149992943\n",
      "Epoch: 0036, total loss=7721.786546707\n",
      "Epoch: 0037, total loss=7721.400003433\n",
      "Epoch: 0038, total loss=7720.983412743\n",
      "Epoch: 0039, total loss=7705.178901672\n",
      "Epoch: 0040, total loss=7586.147266388\n",
      "Epoch: 0041, total loss=7584.309764862\n",
      "Epoch: 0042, total loss=7583.381258011\n",
      "Epoch: 0043, total loss=7582.353350639\n",
      "Epoch: 0044, total loss=7581.238814354\n",
      "Epoch: 0045, total loss=7580.063511848\n",
      "Epoch: 0046, total loss=7578.842926979\n",
      "Epoch: 0047, total loss=7577.584567070\n",
      "Epoch: 0048, total loss=7576.288749695\n",
      "Epoch: 0049, total loss=7574.947859764\n",
      "Epoch: 0050, total loss=7573.540234566\n",
      "Epoch: 0051, total loss=7572.019867897\n"
     ]
    }
   ],
   "source": [
    "# training starting option 1 with GPU\n",
    "# with tf.device('/device:GPU:0'):\n",
    "start = time.time()\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(10000):\n",
    "            total_loss = 0.\n",
    "            for i in range(len(X_train)):\n",
    "                feed = {X_place: X_train, y_place: y_train}\n",
    "                _, loss = sess.run([train_op, cost], feed_dict=feed)\n",
    "                total_loss += loss\n",
    "            print('Epoch: {:04d}, total loss={:.9f}'.format(epoch+1, total_loss))\n",
    "        #     print('Epoch: {:04d}, total loss={:.9f}, entropy: {}'.format(epoch+1, total_loss, cross_entropy))\n",
    "        #     print('predict: {:.6f}'.format(y_pred))\n",
    "        print ('Training complete!')\n",
    "\n",
    "        feed_dict_train = {X_place: X_train}\n",
    "        prediction = sess.run(y_pred, feed_dict=feed_dict_train)\n",
    "        correct = np.equal(np.argmax(prediction,axis=1), np.argmax(y_train,axis=1))\n",
    "        # evaluate the accuracy\n",
    "        accuracy = np.mean(correct)\n",
    "        print('Accuracy on validation: {:2.2%}'.format (accuracy))\n",
    "    save_path = saver.save(sess, model_path+'Titanic_model.ckpt')\n",
    "end = time.time()\n",
    "print('time spend: {:.4f} sec'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = saver.save(sess, model_path+'Titanic_model.ckpt')\n",
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/lambert/Git/Titanic/Titanic_model/Titanic_model.ckpt\n",
      "Accuracy on validation: 81.98%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the training data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path+'Titanic_model.ckpt')\n",
    "    feed_dict_train = {X_place: X_train}\n",
    "    prediction = sess.run(y_pred, feed_dict=feed_dict_train)\n",
    "    correct = np.equal(np.argmax(prediction,axis=1), np.argmax(y_train,axis=1))\n",
    "# evaluate the accuracy\n",
    "accuracy = np.mean(correct)\n",
    "print('Accuracy on validation: {:2.2%}'.format (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/lambert/Git/Titanic/Titanic_model/Titanic_model.ckpt\n",
      "Accuracy on validation: 74.89%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the validate data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path+'Titanic_model.ckpt')\n",
    "    feed_dict_valid = {X_place: X_val}\n",
    "    prediction = sess.run(y_pred, feed_dict=feed_dict_valid)\n",
    "    correct = np.equal(np.argmax(prediction,axis=1), np.argmax(y_val,axis=1))\n",
    "# evaluate the accuracy\n",
    "\n",
    "accuracy = np.mean(correct)\n",
    "print('Accuracy on validation: {:2.2%}'.format (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/lambert/Git/Titanic/Titanic_model/Titanic_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# prediction for test data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path+'Titanic_model.ckpt')\n",
    "    feed_dict_test = {X_place: X_test}\n",
    "    prediction = sess.run(y_pred, feed_dict=feed_dict_test)\n",
    "    y_predict = np.argmax(prediction, axis=1)\n",
    "    y_predict_1 = np.argmin(prediction, axis=1)\n",
    "    \n",
    "# evaluate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengerid = np.array(df_test.PassengerId.tolist())\n",
    "submission = pd.DataFrame({'PassengerId': passengerid, 'Survived': y_predict_1}).set_index('PassengerId')\n",
    "submission.to_csv('submission_tf_GDO_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_accuracy()\n",
    "# plot_example_errors()\n",
    "# optimize(num_iterations=10)\n",
    "# print_accuracy()\n",
    "# plot_example_errors()\n",
    "# plot_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "File_Writer=tf.summary.FileWriter(''/Users/lambert/Documents/Python_code/tensorflow_code/Titanic'\n",
    "                                  ,sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate as much GPU memory based on runtime allocations\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate 40% memory of GPU\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = tf.Session(config=config, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically choose existing in case specified one doesn't exit\n",
    "# allow_soft_placement=True\n",
    "with tf.device('/device:GPU:2'):\n",
    "  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "  c = tf.matmul(a, b)\n",
    "# Creates a session with allow_soft_placement and log_device_placement set\n",
    "# to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device_lib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c74ed16f167f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'device_lib' is not defined"
     ]
    }
   ],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
