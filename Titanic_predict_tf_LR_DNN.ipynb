{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import sys\n",
    "import re\n",
    "import time\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.client import device_lib\n",
    "model_path = '/home/lambert/Git/Titanic/Titanic_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    if pd.isnull(name):\n",
    "        return 'Null'\n",
    "    title_search = re.search('([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1).lower()\n",
    "    else:\n",
    "        return 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = {'mr':1, 'mrs':2, 'mme':2, 'ms':3, 'miss':3, 'mlle':3, 'don':4, 'sir':4, 'jonkheer':4,\n",
    "          'major':4, 'col':4, 'dr':4, 'master':4, 'capt':4, 'dona':5, 'lady':5, 'countess':5,\n",
    "         'rev':6}\n",
    "df_train['Title'] = df_train['Name'].apply(lambda name: titles.get(get_title(name)))\n",
    "df_train['Honor'] = df_train['Title'].apply(lambda title: 1 if title ==4 or title == 5 else 0)\n",
    "df_test['Title'] = df_test['Name'].apply(lambda name: titles.get(get_title(name)))\n",
    "df_test['Honor'] = df_test['Title'].apply(lambda title: 1 if title ==4 or title == 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/pandas/core/indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# 1. Data clearning\n",
    "# df_train.Age.fillna(fill_df_Age, inplace=True)\n",
    "# df_test.Age.fillna(fill_df_Age, inplace=True)\n",
    "for i in range(1,7):\n",
    "    a = df_train[(df_train.Age.isnull()) & (df_train.Title==i)]\n",
    "    df_train.Age.iloc[a.index] = df_train.Age[df_train.Title==i].median()\n",
    "    b = df_test[(df_test.Age.isnull()) & (df_test.Title==i)]\n",
    "    df_test.Age.iloc[b.index] = df_train.Age[df_train.Title==i].median()\n",
    "\n",
    "# Cabin - fill nan with 'fill' and select first cabin\n",
    "df_train.Cabin.fillna('fill',inplace=True)\n",
    "df_train.Cabin = df_train.Cabin.map(lambda x:x.split(' ')[0])\n",
    "df_test.Cabin.fillna('fill', inplace=True)\n",
    "df_test.Cabin = df_test.Cabin.map(lambda x:x.split(' ')[0])\n",
    "\n",
    "# Sex - male: 1, female: 1\n",
    "df_train.Sex.replace({'male':1, 'female':0}, inplace=True)\n",
    "df_test.Sex.replace({'male':1, 'female':0}, inplace=True)\n",
    "\n",
    "df_train = df_train.dropna(axis=0, how='any')\n",
    "df_test.Fare.fillna(df_test.Fare.mean(), inplace=True)\n",
    "\n",
    "# Create a 'Deceased' column for sconed class\n",
    "df_train['Deceased'] = df_train.Survived.apply(lambda s: int(not s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Select the features\n",
    "sFeatures = ['Pclass',\n",
    " 'Sex',\n",
    " 'Age',\n",
    " 'SibSp',\n",
    " 'Parch',\n",
    " 'Fare',             \n",
    " 'Cabin',             \n",
    " 'Embarked',\n",
    " 'Title',\n",
    " 'Honor']\n",
    "LABEL = ['Survived', 'Deceased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Label Encoder\n",
    "# X_test has elements that X doesn't have\n",
    "# create a Cabin_labels cover X and X_test\n",
    "X_Cabin_unique = df_train['Cabin'].unique()\n",
    "X_lack = df_test.Cabin[df_test['Cabin'].isin(X_Cabin_unique)==0].values\n",
    "Cabin_labels = np.append(X_Cabin_unique, X_lack)\n",
    "# print(X_Cabin_unique.shape, X_Cabin_unique)\n",
    "# print(Cabin_labels.shape, Cabin_labels)\n",
    "\n",
    "le_Cabin = LabelEncoder().fit(Cabin_labels)\n",
    "le_Embarked = LabelEncoder().fit(np.array(df_train['Embarked'].tolist()))\n",
    "\n",
    "df_train.loc[:,'Cabin'] = le_Cabin.transform(df_train['Cabin'])\n",
    "df_train.loc[:,'Embarked'] = le_Embarked.transform(df_train['Embarked'])\n",
    "df_test.loc[:,'Cabin'] = le_Cabin.transform(df_test['Cabin'])\n",
    "df_test.loc[:,'Embarked'] = le_Embarked.transform(df_test['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the feature engineer in DF, keep train and label index consistance\n",
    "# Split Validation with the selected features\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(df_train[sFeatures], df_train['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Validation\n",
    "# X_train = df_train[sFeatures]\n",
    "# y_train = df_train['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(X, y, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = X,\n",
    "    y = y,\n",
    "    batch_size = 10,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction_input_fn(X, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = X,\n",
    "    batch_size = 10,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_cols(X):\n",
    "  input_columns = [tf.feature_column.numeric_column(k) for k in X.columns]\n",
    "  return input_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Linear Regression with tf.Estimator framework </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(666, 10)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'Titanic_trained_LR', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x118030e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into Titanic_trained_LR/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 182.829\n",
      "INFO:tensorflow:loss = 3.512393, step = 101 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.306\n",
      "INFO:tensorflow:loss = 1.5293475, step = 201 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.027\n",
      "INFO:tensorflow:loss = 1.8814425, step = 301 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.353\n",
      "INFO:tensorflow:loss = 1.5167223, step = 401 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.278\n",
      "INFO:tensorflow:loss = 2.4931111, step = 501 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.413\n",
      "INFO:tensorflow:loss = 2.112145, step = 601 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.778\n",
      "INFO:tensorflow:loss = 1.0879205, step = 701 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.339\n",
      "INFO:tensorflow:loss = 1.495367, step = 801 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.133\n",
      "INFO:tensorflow:loss = 1.6043568, step = 901 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 521.351\n",
      "INFO:tensorflow:loss = 1.3522375, step = 1001 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.553\n",
      "INFO:tensorflow:loss = 1.9152715, step = 1101 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.289\n",
      "INFO:tensorflow:loss = 2.904585, step = 1201 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.069\n",
      "INFO:tensorflow:loss = 4.1394415, step = 1301 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.261\n",
      "INFO:tensorflow:loss = 2.9263732, step = 1401 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.76\n",
      "INFO:tensorflow:loss = 0.88036406, step = 1501 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.235\n",
      "INFO:tensorflow:loss = 1.5780202, step = 1601 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.219\n",
      "INFO:tensorflow:loss = 1.6778632, step = 1701 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.317\n",
      "INFO:tensorflow:loss = 1.6266569, step = 1801 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.18\n",
      "INFO:tensorflow:loss = 1.2977331, step = 1901 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.384\n",
      "INFO:tensorflow:loss = 1.000805, step = 2001 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.974\n",
      "INFO:tensorflow:loss = 2.0696762, step = 2101 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.604\n",
      "INFO:tensorflow:loss = 1.3913794, step = 2201 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.257\n",
      "INFO:tensorflow:loss = 2.3293204, step = 2301 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.122\n",
      "INFO:tensorflow:loss = 1.3863645, step = 2401 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.316\n",
      "INFO:tensorflow:loss = 3.0984027, step = 2501 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.71\n",
      "INFO:tensorflow:loss = 2.5699203, step = 2601 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.466\n",
      "INFO:tensorflow:loss = 0.67824453, step = 2701 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.017\n",
      "INFO:tensorflow:loss = 1.0393558, step = 2801 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.84\n",
      "INFO:tensorflow:loss = 0.80243635, step = 2901 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.564\n",
      "INFO:tensorflow:loss = 1.8741719, step = 3001 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.76\n",
      "INFO:tensorflow:loss = 1.1147476, step = 3101 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.002\n",
      "INFO:tensorflow:loss = 0.9925828, step = 3201 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.65\n",
      "INFO:tensorflow:loss = 1.0494063, step = 3301 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.837\n",
      "INFO:tensorflow:loss = 1.2411809, step = 3401 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.71\n",
      "INFO:tensorflow:loss = 1.2349794, step = 3501 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.851\n",
      "INFO:tensorflow:loss = 3.570733, step = 3601 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.196\n",
      "INFO:tensorflow:loss = 1.7387892, step = 3701 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.46\n",
      "INFO:tensorflow:loss = 2.7312403, step = 3801 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.245\n",
      "INFO:tensorflow:loss = 0.7195475, step = 3901 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.461\n",
      "INFO:tensorflow:loss = 1.687444, step = 4001 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.402\n",
      "INFO:tensorflow:loss = 1.4619828, step = 4101 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.968\n",
      "INFO:tensorflow:loss = 1.5879142, step = 4201 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.415\n",
      "INFO:tensorflow:loss = 3.215828, step = 4301 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.409\n",
      "INFO:tensorflow:loss = 1.7846185, step = 4401 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.113\n",
      "INFO:tensorflow:loss = 3.021109, step = 4501 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.574\n",
      "INFO:tensorflow:loss = 1.6295905, step = 4601 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.599\n",
      "INFO:tensorflow:loss = 1.6992768, step = 4701 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.439\n",
      "INFO:tensorflow:loss = 1.5437472, step = 4801 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.995\n",
      "INFO:tensorflow:loss = 3.3597922, step = 4901 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.142\n",
      "INFO:tensorflow:loss = 1.3228899, step = 5001 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.825\n",
      "INFO:tensorflow:loss = 2.0592017, step = 5101 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.058\n",
      "INFO:tensorflow:loss = 2.3562357, step = 5201 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.674\n",
      "INFO:tensorflow:loss = 1.714904, step = 5301 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.869\n",
      "INFO:tensorflow:loss = 2.1400099, step = 5401 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.739\n",
      "INFO:tensorflow:loss = 1.2585484, step = 5501 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.842\n",
      "INFO:tensorflow:loss = 3.0273876, step = 5601 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.95\n",
      "INFO:tensorflow:loss = 2.0941396, step = 5701 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.588\n",
      "INFO:tensorflow:loss = 1.2486259, step = 5801 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.479\n",
      "INFO:tensorflow:loss = 1.6688495, step = 5901 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.236\n",
      "INFO:tensorflow:loss = 1.7808003, step = 6001 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.855\n",
      "INFO:tensorflow:loss = 2.3240285, step = 6101 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.364\n",
      "INFO:tensorflow:loss = 1.1131537, step = 6201 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.146\n",
      "INFO:tensorflow:loss = 0.9210433, step = 6301 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.79\n",
      "INFO:tensorflow:loss = 1.5103104, step = 6401 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.622\n",
      "INFO:tensorflow:loss = 0.48832288, step = 6501 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.797\n",
      "INFO:tensorflow:loss = 1.336869, step = 6601 (0.712 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6660 into Titanic_trained_LR/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.133493.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x116e44240>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "OUTDIR_LR = 'Titanic_trained_LR'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "model_LR = tf.estimator.LinearRegressor(\n",
    "      feature_columns = make_feature_cols(X_train), model_dir = OUTDIR)\n",
    "\n",
    "model_LR.train(input_fn = make_input_fn(X_train, y_train, num_epochs = 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Validate the model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rmse(model, name, X, y):\n",
    "  metrics = model.evaluate(input_fn = make_input_fn(X, y, 1))\n",
    "  print('RMSE on {} dataset = {}'.format(name, np.sqrt(metrics['average_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-29-04:15:53\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from Titanic_trained_LR/model.ckpt-6660\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-29-04:15:53\n",
      "INFO:tensorflow:Saving dict for global step 6660: average_loss = 0.16010863, global_step = 6660, loss = 1.5523576\n",
      "RMSE on validation dataset = 0.40013575553894043\n"
     ]
    }
   ],
   "source": [
    "print_rmse(model_LR, 'validation', X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Deep Neural Network regression </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'Titanic_trained_DNN', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1170558d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into Titanic_trained_DNN/model.ckpt.\n",
      "INFO:tensorflow:loss = 5.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 297.618\n",
      "INFO:tensorflow:loss = 1.5687172, step = 101 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.122\n",
      "INFO:tensorflow:loss = 2.6633174, step = 201 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.869\n",
      "INFO:tensorflow:loss = 2.1627471, step = 301 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.608\n",
      "INFO:tensorflow:loss = 2.2055483, step = 401 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.379\n",
      "INFO:tensorflow:loss = 2.8613296, step = 501 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.68\n",
      "INFO:tensorflow:loss = 2.4037654, step = 601 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.37\n",
      "INFO:tensorflow:loss = 2.162193, step = 701 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.167\n",
      "INFO:tensorflow:loss = 2.173275, step = 801 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.579\n",
      "INFO:tensorflow:loss = 2.1645198, step = 901 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.291\n",
      "INFO:tensorflow:loss = 2.637846, step = 1001 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.689\n",
      "INFO:tensorflow:loss = 2.168597, step = 1101 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.731\n",
      "INFO:tensorflow:loss = 2.6529307, step = 1201 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.592\n",
      "INFO:tensorflow:loss = 2.1629648, step = 1301 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.96\n",
      "INFO:tensorflow:loss = 1.9456266, step = 1401 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.369\n",
      "INFO:tensorflow:loss = 2.1736155, step = 1501 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.035\n",
      "INFO:tensorflow:loss = 2.1731467, step = 1601 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.913\n",
      "INFO:tensorflow:loss = 2.164084, step = 1701 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.797\n",
      "INFO:tensorflow:loss = 2.6461692, step = 1801 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.148\n",
      "INFO:tensorflow:loss = 2.4015305, step = 1901 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.206\n",
      "INFO:tensorflow:loss = 3.3675847, step = 2001 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.856\n",
      "INFO:tensorflow:loss = 1.9351486, step = 2101 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.066\n",
      "INFO:tensorflow:loss = 1.9370672, step = 2201 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.844\n",
      "INFO:tensorflow:loss = 2.401974, step = 2301 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.062\n",
      "INFO:tensorflow:loss = 2.9057565, step = 2401 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.342\n",
      "INFO:tensorflow:loss = 2.4014683, step = 2501 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.611\n",
      "INFO:tensorflow:loss = 2.4044366, step = 2601 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.757\n",
      "INFO:tensorflow:loss = 1.6718287, step = 2701 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.027\n",
      "INFO:tensorflow:loss = 2.163066, step = 2801 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.838\n",
      "INFO:tensorflow:loss = 2.6353135, step = 2901 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.547\n",
      "INFO:tensorflow:loss = 2.6205924, step = 3001 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.041\n",
      "INFO:tensorflow:loss = 2.1619573, step = 3101 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.408\n",
      "INFO:tensorflow:loss = 2.4065962, step = 3201 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.556\n",
      "INFO:tensorflow:loss = 2.6240048, step = 3301 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.059\n",
      "INFO:tensorflow:loss = 3.1291785, step = 3401 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.191\n",
      "INFO:tensorflow:loss = 1.9395778, step = 3501 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.195\n",
      "INFO:tensorflow:loss = 1.9468167, step = 3601 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.045\n",
      "INFO:tensorflow:loss = 2.154723, step = 3701 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.546\n",
      "INFO:tensorflow:loss = 2.6423738, step = 3801 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 529.558\n",
      "INFO:tensorflow:loss = 2.170783, step = 3901 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.153\n",
      "INFO:tensorflow:loss = 2.4031315, step = 4001 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.768\n",
      "INFO:tensorflow:loss = 2.1652036, step = 4101 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.175\n",
      "INFO:tensorflow:loss = 1.9193547, step = 4201 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.204\n",
      "INFO:tensorflow:loss = 2.1690228, step = 4301 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.208\n",
      "INFO:tensorflow:loss = 2.6489854, step = 4401 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.741\n",
      "INFO:tensorflow:loss = 2.894692, step = 4501 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.288\n",
      "INFO:tensorflow:loss = 2.6358283, step = 4601 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.319\n",
      "INFO:tensorflow:loss = 2.40106, step = 4701 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.485\n",
      "INFO:tensorflow:loss = 1.9416796, step = 4801 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.959\n",
      "INFO:tensorflow:loss = 2.4058728, step = 4901 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.516\n",
      "INFO:tensorflow:loss = 1.9340239, step = 5001 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.986\n",
      "INFO:tensorflow:loss = 2.1642857, step = 5101 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.798\n",
      "INFO:tensorflow:loss = 2.6286056, step = 5201 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.975\n",
      "INFO:tensorflow:loss = 2.646499, step = 5301 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.093\n",
      "INFO:tensorflow:loss = 1.9440317, step = 5401 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.156\n",
      "INFO:tensorflow:loss = 2.4037185, step = 5501 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.223\n",
      "INFO:tensorflow:loss = 1.396216, step = 5601 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.798\n",
      "INFO:tensorflow:loss = 2.4035666, step = 5701 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.206\n",
      "INFO:tensorflow:loss = 2.173207, step = 5801 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.323\n",
      "INFO:tensorflow:loss = 2.6275988, step = 5901 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.496\n",
      "INFO:tensorflow:loss = 2.40549, step = 6001 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.08\n",
      "INFO:tensorflow:loss = 3.1444812, step = 6101 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.93\n",
      "INFO:tensorflow:loss = 2.1679606, step = 6201 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 511.052\n",
      "INFO:tensorflow:loss = 2.403995, step = 6301 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 532.232\n",
      "INFO:tensorflow:loss = 2.1664987, step = 6401 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.463\n",
      "INFO:tensorflow:loss = 2.4028192, step = 6501 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.427\n",
      "INFO:tensorflow:loss = 1.9589474, step = 6601 (0.504 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6660 into Titanic_trained_DNN/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.1643336.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x117398d68>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTDIR_DNN = 'Titanic_trained_DNN'\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "shutil.rmtree(OUTDIR_DNN, ignore_errors = True) # start fresh each time\n",
    "model_DNN = tf.estimator.DNNRegressor(hidden_units = [32, 8, 2],\n",
    "      feature_columns = make_feature_cols(X_train), model_dir = OUTDIR_DNN)\n",
    "model_DNN.train(input_fn = make_input_fn(X_train, y_train, num_epochs = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-29-04:24:21\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from Titanic_trained_DNN/model.ckpt-6660\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-29-04:24:22\n",
      "INFO:tensorflow:Saving dict for global step 6660: average_loss = 0.23695736, global_step = 6660, loss = 2.2974563\n",
      "RMSE on validation dataset = 0.48678267002105713\n"
     ]
    }
   ],
   "source": [
    "print_rmse(model_DNN, 'validation', X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow variables\n",
    "# with tf.device('/device:GPU:0'):\n",
    "features= len(sFeatures)\n",
    "X_place = tf.placeholder(tf.float32, shape=[None,features])\n",
    "y_place = tf.placeholder(tf.float32, shape=[None,2])\n",
    "W = tf.Variable(tf.random_normal([features, 2]), name='weights')\n",
    "b = tf.Variable(tf.zeros(2), name='bias')\n",
    "logits = tf.matmul(X_place, W) + b\n",
    "y_pred = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Entropy\n",
    "# with tf.device('/device:GPU:0'):\n",
    "learning_rate = 0.001\n",
    "cross_entropy = -tf.reduce_sum(y_place * tf.log(y_pred + 1e-10), axis=1)\n",
    "# cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y_train)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.Session()\n",
    "# sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training starting option 1\n",
    "# for epoch in range(10000):\n",
    "#     total_loss = 0.\n",
    "#     x_batch, y_batch = next_batch(batch_size, X_train, y_train)\n",
    "#     feed_dict_train = {X_place: x_batch, y_place: y_batch}\n",
    "#     _, loss = sess.run([train_op, cost], feed_dict=feed_dict_train)\n",
    "#     total_loss += loss\n",
    "#     print('Epoch: {:04d}, total loss={:.9f}'.format(epoch+1, total_loss))\n",
    "# #     print('Epoch: {:04d}, total loss={:.9f}, entropy: {}'.format(epoch+1, total_loss, cross_entropy))\n",
    "# #     print('predict: {:.6f}'.format(y_pred))\n",
    "# print ('Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training starting option 1 with CPU\n",
    "# for epoch in range(100):\n",
    "#     total_loss = 0.\n",
    "#     for i in range(len(X_train)):\n",
    "#         feed = {X_place: X_train, y_place: y_train}\n",
    "#         _, loss = sess.run([train_op, cost], feed_dict=feed)\n",
    "#         total_loss += loss\n",
    "#     print('Epoch: {:04d}, total loss={:.9f}'.format(epoch+1, total_loss))\n",
    "# #     print('Epoch: {:04d}, total loss={:.9f}, entropy: {}'.format(epoch+1, total_loss, cross_entropy))\n",
    "# #     print('predict: {:.6f}'.format(y_pred))\n",
    "# print ('Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001, total loss=7741.516098022\n",
      "Epoch: 0002, total loss=7738.829321861\n",
      "Epoch: 0003, total loss=7734.809428215\n",
      "Epoch: 0004, total loss=7731.230428696\n",
      "Epoch: 0005, total loss=7730.431954384\n",
      "Epoch: 0006, total loss=7730.153929710\n",
      "Epoch: 0007, total loss=7729.909674644\n",
      "Epoch: 0008, total loss=7729.665932655\n",
      "Epoch: 0009, total loss=7729.419364929\n",
      "Epoch: 0010, total loss=7729.170191765\n",
      "Epoch: 0011, total loss=7728.918432236\n",
      "Epoch: 0012, total loss=7728.664295197\n",
      "Epoch: 0013, total loss=7728.407405853\n",
      "Epoch: 0014, total loss=7728.149026871\n",
      "Epoch: 0015, total loss=7727.888969421\n",
      "Epoch: 0016, total loss=7727.626473427\n",
      "Epoch: 0017, total loss=7727.363004684\n",
      "Epoch: 0018, total loss=7727.097887993\n",
      "Epoch: 0019, total loss=7726.830873489\n",
      "Epoch: 0020, total loss=7726.563403130\n",
      "Epoch: 0021, total loss=7726.293632507\n",
      "Epoch: 0022, total loss=7726.022218704\n",
      "Epoch: 0023, total loss=7725.749572754\n",
      "Epoch: 0024, total loss=7725.473988533\n",
      "Epoch: 0025, total loss=7725.196638107\n",
      "Epoch: 0026, total loss=7724.916168213\n",
      "Epoch: 0027, total loss=7724.632925987\n",
      "Epoch: 0028, total loss=7724.346180916\n",
      "Epoch: 0029, total loss=7724.055155754\n",
      "Epoch: 0030, total loss=7723.758786201\n",
      "Epoch: 0031, total loss=7723.456103325\n",
      "Epoch: 0032, total loss=7723.145912170\n",
      "Epoch: 0033, total loss=7722.826562881\n",
      "Epoch: 0034, total loss=7722.495479584\n",
      "Epoch: 0035, total loss=7722.149992943\n",
      "Epoch: 0036, total loss=7721.786546707\n",
      "Epoch: 0037, total loss=7721.400003433\n",
      "Epoch: 0038, total loss=7720.983412743\n",
      "Epoch: 0039, total loss=7705.178901672\n",
      "Epoch: 0040, total loss=7586.147266388\n",
      "Epoch: 0041, total loss=7584.309764862\n",
      "Epoch: 0042, total loss=7583.381258011\n",
      "Epoch: 0043, total loss=7582.353350639\n",
      "Epoch: 0044, total loss=7581.238814354\n",
      "Epoch: 0045, total loss=7580.063511848\n",
      "Epoch: 0046, total loss=7578.842926979\n",
      "Epoch: 0047, total loss=7577.584567070\n",
      "Epoch: 0048, total loss=7576.288749695\n",
      "Epoch: 0049, total loss=7574.947859764\n",
      "Epoch: 0050, total loss=7573.540234566\n",
      "Epoch: 0051, total loss=7572.019867897\n"
     ]
    }
   ],
   "source": [
    "# training starting option 1 with GPU\n",
    "# with tf.device('/device:GPU:0'):\n",
    "start = time.time()\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(10000):\n",
    "            total_loss = 0.\n",
    "            for i in range(len(X_train)):\n",
    "                feed = {X_place: X_train, y_place: y_train}\n",
    "                _, loss = sess.run([train_op, cost], feed_dict=feed)\n",
    "                total_loss += loss\n",
    "            print('Epoch: {:04d}, total loss={:.9f}'.format(epoch+1, total_loss))\n",
    "        #     print('Epoch: {:04d}, total loss={:.9f}, entropy: {}'.format(epoch+1, total_loss, cross_entropy))\n",
    "        #     print('predict: {:.6f}'.format(y_pred))\n",
    "        print ('Training complete!')\n",
    "\n",
    "        feed_dict_train = {X_place: X_train}\n",
    "        prediction = sess.run(y_pred, feed_dict=feed_dict_train)\n",
    "        correct = np.equal(np.argmax(prediction,axis=1), np.argmax(y_train,axis=1))\n",
    "        # evaluate the accuracy\n",
    "        accuracy = np.mean(correct)\n",
    "        print('Accuracy on validation: {:2.2%}'.format (accuracy))\n",
    "    save_path = saver.save(sess, model_path+'Titanic_model.ckpt')\n",
    "end = time.time()\n",
    "print('time spend: {:.4f} sec'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = saver.save(sess, model_path+'Titanic_model.ckpt')\n",
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/lambert/Git/Titanic/Titanic_model/Titanic_model.ckpt\n",
      "Accuracy on validation: 81.98%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the training data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path+'Titanic_model.ckpt')\n",
    "    feed_dict_train = {X_place: X_train}\n",
    "    prediction = sess.run(y_pred, feed_dict=feed_dict_train)\n",
    "    correct = np.equal(np.argmax(prediction,axis=1), np.argmax(y_train,axis=1))\n",
    "# evaluate the accuracy\n",
    "accuracy = np.mean(correct)\n",
    "print('Accuracy on validation: {:2.2%}'.format (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/lambert/Git/Titanic/Titanic_model/Titanic_model.ckpt\n",
      "Accuracy on validation: 74.89%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the validate data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path+'Titanic_model.ckpt')\n",
    "    feed_dict_valid = {X_place: X_val}\n",
    "    prediction = sess.run(y_pred, feed_dict=feed_dict_valid)\n",
    "    correct = np.equal(np.argmax(prediction,axis=1), np.argmax(y_val,axis=1))\n",
    "# evaluate the accuracy\n",
    "\n",
    "accuracy = np.mean(correct)\n",
    "print('Accuracy on validation: {:2.2%}'.format (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/lambert/Git/Titanic/Titanic_model/Titanic_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# prediction for test data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path+'Titanic_model.ckpt')\n",
    "    feed_dict_test = {X_place: X_test}\n",
    "    prediction = sess.run(y_pred, feed_dict=feed_dict_test)\n",
    "    y_predict = np.argmax(prediction, axis=1)\n",
    "    y_predict_1 = np.argmin(prediction, axis=1)\n",
    "    \n",
    "# evaluate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengerid = np.array(df_test.PassengerId.tolist())\n",
    "submission = pd.DataFrame({'PassengerId': passengerid, 'Survived': y_predict_1}).set_index('PassengerId')\n",
    "submission.to_csv('submission_tf_GDO_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_accuracy()\n",
    "# plot_example_errors()\n",
    "# optimize(num_iterations=10)\n",
    "# print_accuracy()\n",
    "# plot_example_errors()\n",
    "# plot_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "File_Writer=tf.summary.FileWriter(''/Users/lambert/Documents/Python_code/tensorflow_code/Titanic'\n",
    "                                  ,sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate as much GPU memory based on runtime allocations\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate 40% memory of GPU\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = tf.Session(config=config, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically choose existing in case specified one doesn't exit\n",
    "# allow_soft_placement=True\n",
    "with tf.device('/device:GPU:2'):\n",
    "  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "  c = tf.matmul(a, b)\n",
    "# Creates a session with allow_soft_placement and log_device_placement set\n",
    "# to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device_lib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c74ed16f167f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'device_lib' is not defined"
     ]
    }
   ],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
