{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Titanic_predict_tf_LR_DNN </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import sys\n",
    "import re\n",
    "import time\n",
    "import shutil\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.metrics import accuracy_score\n",
    "model_path = '/home/lambert/Git/Titanic/Titanic_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    if pd.isnull(name):\n",
    "        return 'Null'\n",
    "    title_search = re.search('([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1).lower()\n",
    "    else:\n",
    "        return 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = {'mr':1, 'mrs':2, 'mme':2, 'ms':3, 'miss':3, 'mlle':3, 'don':4, 'sir':4, 'jonkheer':4,\n",
    "          'major':4, 'col':4, 'dr':4, 'master':4, 'capt':4, 'dona':5, 'lady':5, 'countess':5,\n",
    "         'rev':6}\n",
    "df_train['Title'] = df_train['Name'].apply(lambda name: titles.get(get_title(name)))\n",
    "df_train['Honor'] = df_train['Title'].apply(lambda title: 1 if title ==4 or title == 5 else 0)\n",
    "df_test['Title'] = df_test['Name'].apply(lambda name: titles.get(get_title(name)))\n",
    "df_test['Honor'] = df_test['Title'].apply(lambda title: 1 if title ==4 or title == 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/pandas/core/indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# 1. Data clearning\n",
    "# df_train.Age.fillna(fill_df_Age, inplace=True)\n",
    "# df_test.Age.fillna(fill_df_Age, inplace=True)\n",
    "for i in range(1,7):\n",
    "    a = df_train[(df_train.Age.isnull()) & (df_train.Title==i)]\n",
    "    df_train.Age.iloc[a.index] = df_train.Age[df_train.Title==i].median()\n",
    "    b = df_test[(df_test.Age.isnull()) & (df_test.Title==i)]\n",
    "    df_test.Age.iloc[b.index] = df_train.Age[df_train.Title==i].median()\n",
    "\n",
    "# Cabin - fill nan with 'fill' and select first cabin\n",
    "df_train.Cabin.fillna('fill',inplace=True)\n",
    "df_train.Cabin = df_train.Cabin.map(lambda x:x.split(' ')[0])\n",
    "df_test.Cabin.fillna('fill', inplace=True)\n",
    "df_test.Cabin = df_test.Cabin.map(lambda x:x.split(' ')[0])\n",
    "\n",
    "# Sex - male: 1, female: 1\n",
    "df_train.Sex.replace({'male':1, 'female':0}, inplace=True)\n",
    "df_test.Sex.replace({'male':1, 'female':0}, inplace=True)\n",
    "\n",
    "df_train = df_train.dropna(axis=0, how='any')\n",
    "df_test.Fare.fillna(df_test.Fare.mean(), inplace=True)\n",
    "\n",
    "# Create a 'Deceased' column for sconed class\n",
    "df_train['Deceased'] = df_train.Survived.apply(lambda s: int(not s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Select the features\n",
    "sFeatures = ['Pclass',\n",
    " 'Sex',\n",
    " 'Age',\n",
    " 'SibSp',\n",
    " 'Parch',\n",
    " 'Fare',             \n",
    " 'Cabin',             \n",
    " 'Embarked',\n",
    " 'Title',\n",
    " 'Honor']\n",
    "LABEL = ['Survived', 'Deceased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Label Encoder\n",
    "# X_test has elements that X doesn't have\n",
    "# create a Cabin_labels cover X and X_test\n",
    "X_Cabin_unique = df_train['Cabin'].unique()\n",
    "X_lack = df_test.Cabin[df_test['Cabin'].isin(X_Cabin_unique)==0].values\n",
    "Cabin_labels = np.append(X_Cabin_unique, X_lack)\n",
    "# print(X_Cabin_unique.shape, X_Cabin_unique)\n",
    "# print(Cabin_labels.shape, Cabin_labels)\n",
    "\n",
    "le_Cabin = LabelEncoder().fit(Cabin_labels)\n",
    "le_Embarked = LabelEncoder().fit(np.array(df_train['Embarked'].tolist()))\n",
    "\n",
    "df_train.loc[:,'Cabin'] = le_Cabin.transform(df_train['Cabin'])\n",
    "df_train.loc[:,'Embarked'] = le_Embarked.transform(df_train['Embarked'])\n",
    "df_test.loc[:,'Cabin'] = le_Cabin.transform(df_test['Cabin'])\n",
    "df_test.loc[:,'Embarked'] = le_Embarked.transform(df_test['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the feature engineer in DF, keep train and label index consistance\n",
    "# Split Validation with the selected features\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(df_train[sFeatures], df_train['Survived'])\n",
    "X_test = df_test[sFeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Validation\n",
    "# X_train = df_train[sFeatures]\n",
    "# y_train = df_train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_cols(X):\n",
    "  return [tf.feature_column.numeric_column(k) for k in X.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training and test input function\n",
    "def make_input_fn(X, y, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = X,\n",
    "    y = y,\n",
    "    batch_size = 128,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction_input_fn(X, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = X,\n",
    "    batch_size = 1,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = False,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Linear Regression with tf.Estimator framework </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(666, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'Titanic_trained_LC', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1198b64a8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into Titanic_trained_LC/model.ckpt.\n",
      "INFO:tensorflow:loss = 88.722855, step = 1\n",
      "INFO:tensorflow:global_step/sec: 189.572\n",
      "INFO:tensorflow:loss = 56.244118, step = 101 (0.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.832\n",
      "INFO:tensorflow:loss = 65.35011, step = 201 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.409\n",
      "INFO:tensorflow:loss = 70.81287, step = 301 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.341\n",
      "INFO:tensorflow:loss = 61.797024, step = 401 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.505\n",
      "INFO:tensorflow:loss = 64.311134, step = 501 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.02\n",
      "INFO:tensorflow:loss = 66.24104, step = 601 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.091\n",
      "INFO:tensorflow:loss = 76.05946, step = 701 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.66\n",
      "INFO:tensorflow:loss = 60.238457, step = 801 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.84\n",
      "INFO:tensorflow:loss = 67.30427, step = 901 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.662\n",
      "INFO:tensorflow:loss = 51.220657, step = 1001 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.954\n",
      "INFO:tensorflow:loss = 60.93091, step = 1101 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.036\n",
      "INFO:tensorflow:loss = 58.192574, step = 1201 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.467\n",
      "INFO:tensorflow:loss = 63.379997, step = 1301 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.498\n",
      "INFO:tensorflow:loss = 54.32528, step = 1401 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.18\n",
      "INFO:tensorflow:loss = 62.761402, step = 1501 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.64\n",
      "INFO:tensorflow:loss = 54.08466, step = 1601 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.861\n",
      "INFO:tensorflow:loss = 54.92408, step = 1701 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.989\n",
      "INFO:tensorflow:loss = 55.43705, step = 1801 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.394\n",
      "INFO:tensorflow:loss = 75.17038, step = 1901 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.471\n",
      "INFO:tensorflow:loss = 66.61484, step = 2001 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.537\n",
      "INFO:tensorflow:loss = 49.96134, step = 2101 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.767\n",
      "INFO:tensorflow:loss = 47.575405, step = 2201 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.02\n",
      "INFO:tensorflow:loss = 72.07554, step = 2301 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.22\n",
      "INFO:tensorflow:loss = 59.242218, step = 2401 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.706\n",
      "INFO:tensorflow:loss = 51.310516, step = 2501 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.836\n",
      "INFO:tensorflow:loss = 69.12091, step = 2601 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.822\n",
      "INFO:tensorflow:loss = 58.301723, step = 2701 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.168\n",
      "INFO:tensorflow:loss = 66.94343, step = 2801 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.718\n",
      "INFO:tensorflow:loss = 64.679474, step = 2901 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.452\n",
      "INFO:tensorflow:loss = 64.06388, step = 3001 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.666\n",
      "INFO:tensorflow:loss = 55.514153, step = 3101 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.508\n",
      "INFO:tensorflow:loss = 42.842278, step = 3201 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.101\n",
      "INFO:tensorflow:loss = 50.99975, step = 3301 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.412\n",
      "INFO:tensorflow:loss = 61.37114, step = 3401 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.337\n",
      "INFO:tensorflow:loss = 70.62535, step = 3501 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.177\n",
      "INFO:tensorflow:loss = 63.264782, step = 3601 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.98\n",
      "INFO:tensorflow:loss = 78.70808, step = 3701 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.128\n",
      "INFO:tensorflow:loss = 52.23816, step = 3801 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.174\n",
      "INFO:tensorflow:loss = 68.59589, step = 3901 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.243\n",
      "INFO:tensorflow:loss = 63.714336, step = 4001 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.312\n",
      "INFO:tensorflow:loss = 63.077736, step = 4101 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.204\n",
      "INFO:tensorflow:loss = 48.718925, step = 4201 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.111\n",
      "INFO:tensorflow:loss = 55.346565, step = 4301 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.887\n",
      "INFO:tensorflow:loss = 59.064804, step = 4401 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.609\n",
      "INFO:tensorflow:loss = 65.726494, step = 4501 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.931\n",
      "INFO:tensorflow:loss = 45.399254, step = 4601 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.839\n",
      "INFO:tensorflow:loss = 56.016243, step = 4701 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.592\n",
      "INFO:tensorflow:loss = 55.190735, step = 4801 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.235\n",
      "INFO:tensorflow:loss = 53.168945, step = 4901 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.945\n",
      "INFO:tensorflow:loss = 59.30948, step = 5001 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.489\n",
      "INFO:tensorflow:loss = 58.319786, step = 5101 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.217\n",
      "INFO:tensorflow:loss = 58.46741, step = 5201 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.025\n",
      "INFO:tensorflow:loss = 59.451202, step = 5301 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.984\n",
      "INFO:tensorflow:loss = 64.25377, step = 5401 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.274\n",
      "INFO:tensorflow:loss = 57.398285, step = 5501 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.929\n",
      "INFO:tensorflow:loss = 62.88825, step = 5601 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.274\n",
      "INFO:tensorflow:loss = 50.42502, step = 5701 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.316\n",
      "INFO:tensorflow:loss = 61.189857, step = 5801 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.359\n",
      "INFO:tensorflow:loss = 68.207596, step = 5901 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.912\n",
      "INFO:tensorflow:loss = 56.889023, step = 6001 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.647\n",
      "INFO:tensorflow:loss = 56.274498, step = 6101 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.803\n",
      "INFO:tensorflow:loss = 66.63135, step = 6201 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.619\n",
      "INFO:tensorflow:loss = 63.136196, step = 6301 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.488\n",
      "INFO:tensorflow:loss = 65.3122, step = 6401 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.448\n",
      "INFO:tensorflow:loss = 51.90803, step = 6501 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.374\n",
      "INFO:tensorflow:loss = 56.336636, step = 6601 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.219\n",
      "INFO:tensorflow:loss = 45.11618, step = 6701 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.868\n",
      "INFO:tensorflow:loss = 60.8722, step = 6801 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.299\n",
      "INFO:tensorflow:loss = 55.574154, step = 6901 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.057\n",
      "INFO:tensorflow:loss = 53.404655, step = 7001 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.004\n",
      "INFO:tensorflow:loss = 55.10351, step = 7101 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.442\n",
      "INFO:tensorflow:loss = 54.35866, step = 7201 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.789\n",
      "INFO:tensorflow:loss = 59.255688, step = 7301 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 56.595444, step = 7401 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.869\n",
      "INFO:tensorflow:loss = 54.80037, step = 7501 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.087\n",
      "INFO:tensorflow:loss = 55.027245, step = 7601 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.343\n",
      "INFO:tensorflow:loss = 50.44211, step = 7701 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.769\n",
      "INFO:tensorflow:loss = 56.44274, step = 7801 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.219\n",
      "INFO:tensorflow:loss = 50.994373, step = 7901 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.71\n",
      "INFO:tensorflow:loss = 74.778046, step = 8001 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.771\n",
      "INFO:tensorflow:loss = 60.49221, step = 8101 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.185\n",
      "INFO:tensorflow:loss = 61.860382, step = 8201 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.108\n",
      "INFO:tensorflow:loss = 63.79139, step = 8301 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.224\n",
      "INFO:tensorflow:loss = 58.065193, step = 8401 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.196\n",
      "INFO:tensorflow:loss = 59.000504, step = 8501 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.14\n",
      "INFO:tensorflow:loss = 54.803, step = 8601 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.29\n",
      "INFO:tensorflow:loss = 64.29042, step = 8701 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.61\n",
      "INFO:tensorflow:loss = 63.029156, step = 8801 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.353\n",
      "INFO:tensorflow:loss = 57.363136, step = 8901 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.919\n",
      "INFO:tensorflow:loss = 47.598183, step = 9001 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.755\n",
      "INFO:tensorflow:loss = 52.58024, step = 9101 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.853\n",
      "INFO:tensorflow:loss = 68.26222, step = 9201 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.296\n",
      "INFO:tensorflow:loss = 52.36993, step = 9301 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.331\n",
      "INFO:tensorflow:loss = 58.819595, step = 9401 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.433\n",
      "INFO:tensorflow:loss = 55.000156, step = 9501 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.087\n",
      "INFO:tensorflow:loss = 59.055542, step = 9601 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.29\n",
      "INFO:tensorflow:loss = 58.782074, step = 9701 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.895\n",
      "INFO:tensorflow:loss = 56.176964, step = 9801 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.268\n",
      "INFO:tensorflow:loss = 62.561214, step = 9901 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.073\n",
      "INFO:tensorflow:loss = 45.308517, step = 10001 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.752\n",
      "INFO:tensorflow:loss = 53.749317, step = 10101 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.445\n",
      "INFO:tensorflow:loss = 61.966774, step = 10201 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.169\n",
      "INFO:tensorflow:loss = 59.855797, step = 10301 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.73\n",
      "INFO:tensorflow:loss = 49.516457, step = 10401 (0.300 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10407 into Titanic_trained_LC/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 12.515991.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x12426b8d0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "OUTDIR_LR = 'Titanic_trained_LC'\n",
    "shutil.rmtree(OUTDIR_LR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "model_LR = tf.estimator.LinearClassifier(\n",
    "    feature_columns = make_feature_cols(X_train), model_dir = OUTDIR_LR)\n",
    "\n",
    "# model_LR = tf.estimator.LinearRegressor(\n",
    "#       feature_columns = make_feature_cols(X_train), model_dir = OUTDIR_LR)\n",
    "\n",
    "model_LR.train(input_fn = make_input_fn(X_train, y_train, num_epochs = 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step :  10407\n",
      "linear/linear_model/Age/weights :  [[-0.01193987]]\n",
      "linear/linear_model/Age/weights/part_0/Ftrl :  [[6.093922e+08]]\n",
      "linear/linear_model/Age/weights/part_0/Ftrl_1 :  [[1473.7301]]\n",
      "linear/linear_model/Cabin/weights :  [[0.00034001]]\n",
      "linear/linear_model/Cabin/weights/part_0/Ftrl :  [[1.9154797e+10]]\n",
      "linear/linear_model/Cabin/weights/part_0/Ftrl_1 :  [[-235.29172]]\n",
      "linear/linear_model/Embarked/weights :  [[-0.05420135]]\n",
      "linear/linear_model/Embarked/weights/part_0/Ftrl :  [[1760927.6]]\n",
      "linear/linear_model/Embarked/weights/part_0/Ftrl_1 :  [[359.6258]]\n",
      "linear/linear_model/Fare/weights :  [[0.01205712]]\n",
      "linear/linear_model/Fare/weights/part_0/Ftrl :  [[1.04833504e+09]]\n",
      "linear/linear_model/Fare/weights/part_0/Ftrl_1 :  [[-1951.928]]\n",
      "linear/linear_model/Honor/weights :  [[1.9490682]]\n",
      "linear/linear_model/Honor/weights/part_0/Ftrl :  [[15344.565]]\n",
      "linear/linear_model/Honor/weights/part_0/Ftrl_1 :  [[-1207.1864]]\n",
      "linear/linear_model/Parch/weights :  [[-0.2595531]]\n",
      "linear/linear_model/Parch/weights/part_0/Ftrl :  [[266497.78]]\n",
      "linear/linear_model/Parch/weights/part_0/Ftrl_1 :  [[669.951]]\n",
      "linear/linear_model/Pclass/weights :  [[-0.5306801]]\n",
      "linear/linear_model/Pclass/weights/part_0/Ftrl :  [[3865257.2]]\n",
      "linear/linear_model/Pclass/weights/part_0/Ftrl_1 :  [[5216.654]]\n",
      "linear/linear_model/Sex/weights :  [[-2.7337518]]\n",
      "linear/linear_model/Sex/weights/part_0/Ftrl :  [[289429.5]]\n",
      "linear/linear_model/Sex/weights/part_0/Ftrl_1 :  [[7353.608]]\n",
      "linear/linear_model/SibSp/weights :  [[-0.45035738]]\n",
      "linear/linear_model/SibSp/weights/part_0/Ftrl :  [[301294.4]]\n",
      "linear/linear_model/SibSp/weights/part_0/Ftrl_1 :  [[1236.0123]]\n",
      "linear/linear_model/Title/weights :  [[0.04352037]]\n",
      "linear/linear_model/Title/weights/part_0/Ftrl :  [[2810364.2]]\n",
      "linear/linear_model/Title/weights/part_0/Ftrl_1 :  [[-364.79083]]\n",
      "linear/linear_model/bias_weights :  [2.589443]\n",
      "linear/linear_model/bias_weights/part_0/Ftrl :  [706431.06]\n",
      "linear/linear_model/bias_weights/part_0/Ftrl_1 :  [-10882.063]\n"
     ]
    }
   ],
   "source": [
    "# Get all weights\n",
    "for i,name in enumerate(model_LR.get_variable_names()):\n",
    "    print(name,\": \", model_LR.get_variable_value(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Validate the model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rmse(model, name, X, y):\n",
    "  metrics = model.evaluate(input_fn = make_input_fn(X, y, 1))\n",
    "  print('RMSE on {} dataset = {}'.format(name, np.sqrt(metrics['average_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-06-02-15:37:50\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from Titanic_trained_LC/model.ckpt-10407\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-06-02-15:37:51\n",
      "INFO:tensorflow:Saving dict for global step 10407: accuracy = 0.8206278, accuracy_baseline = 0.5650224, auc = 0.8963754, auc_precision_recall = 0.88440686, average_loss = 0.40983117, global_step = 10407, label/mean = 0.4349776, loss = 45.696175, prediction/mean = 0.40405366\n",
      "RMSE on validation dataset = 0.6401805877685547\n"
     ]
    }
   ],
   "source": [
    "print_rmse(model_LR, 'validation', X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Prediction X_test </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from Titanic_trained_LC/model.ckpt-10407\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "New Samples, Class Predictions:    [0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_iter = model_LR.predict(input_fn = make_prediction_input_fn(X_test,1))\n",
    "# print([pred['predictions'][0] for pred in list(itertools.islice(preds_iter, 5))])\n",
    "predicted_classes = [np.int(p[\"classes\"]) for p in preds_iter]\n",
    "print(\"New Samples, Class Predictions:    {}\\n\".format(predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengerid = np.array(df_test.PassengerId.tolist())\n",
    "submission = pd.DataFrame({'PassengerId': passengerid, 'Survived': predicted_classes}).set_index('PassengerId')\n",
    "submission.to_csv('submission_tf_LR_v4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed_dict_train = {X_place: X_train}\n",
    "#         prediction = sess.run(y_pred, feed_dict=feed_dict_train)\n",
    "#         correct = np.equal(np.argmax(prediction,axis=1), np.argmax(y_train,axis=1))\n",
    "#         # evaluate the accuracy\n",
    "#         accuracy = np.mean(correct)\n",
    "#         print('Accuracy on validation: {:2.2%}'.format (accuracy))\n",
    "#     save_path = saver.save(sess, model_path+'Titanic_model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Deep Neural Network regression </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'Titanic_trained_DNN', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1241aa5c0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into Titanic_trained_DNN/model.ckpt.\n",
      "INFO:tensorflow:loss = 1660.9915, step = 1\n",
      "INFO:tensorflow:global_step/sec: 177.093\n",
      "INFO:tensorflow:loss = 87.92992, step = 101 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.567\n",
      "INFO:tensorflow:loss = 84.158745, step = 201 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.678\n",
      "INFO:tensorflow:loss = 85.24682, step = 301 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.265\n",
      "INFO:tensorflow:loss = 84.707, step = 401 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.672\n",
      "INFO:tensorflow:loss = 84.15369, step = 501 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.512\n",
      "INFO:tensorflow:loss = 84.15498, step = 601 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.976\n",
      "INFO:tensorflow:loss = 88.05606, step = 701 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.67\n",
      "INFO:tensorflow:loss = 83.598076, step = 801 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.877\n",
      "INFO:tensorflow:loss = 84.15512, step = 901 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.345\n",
      "INFO:tensorflow:loss = 81.37717, step = 1001 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.157\n",
      "INFO:tensorflow:loss = 88.59322, step = 1101 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.136\n",
      "INFO:tensorflow:loss = 84.1532, step = 1201 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.703\n",
      "INFO:tensorflow:loss = 86.37641, step = 1301 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.064\n",
      "INFO:tensorflow:loss = 85.81859, step = 1401 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.692\n",
      "INFO:tensorflow:loss = 86.37105, step = 1501 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.958\n",
      "INFO:tensorflow:loss = 79.18591, step = 1601 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.261\n",
      "INFO:tensorflow:loss = 81.94259, step = 1701 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.749\n",
      "INFO:tensorflow:loss = 89.13222, step = 1801 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.273\n",
      "INFO:tensorflow:loss = 86.9314, step = 1901 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.009\n",
      "INFO:tensorflow:loss = 88.58982, step = 2001 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.16\n",
      "INFO:tensorflow:loss = 85.26551, step = 2101 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.307\n",
      "INFO:tensorflow:loss = 78.06038, step = 2201 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.55\n",
      "INFO:tensorflow:loss = 84.70721, step = 2301 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.729\n",
      "INFO:tensorflow:loss = 82.49205, step = 2401 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.182\n",
      "INFO:tensorflow:loss = 82.493965, step = 2501 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.342\n",
      "INFO:tensorflow:loss = 85.263794, step = 2601 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.063\n",
      "INFO:tensorflow:loss = 83.5999, step = 2701 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.632\n",
      "INFO:tensorflow:loss = 86.92734, step = 2801 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.208\n",
      "INFO:tensorflow:loss = 82.493355, step = 2901 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.107\n",
      "INFO:tensorflow:loss = 90.26602, step = 3001 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.082\n",
      "INFO:tensorflow:loss = 84.70709, step = 3101 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.491\n",
      "INFO:tensorflow:loss = 80.8311, step = 3201 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.411\n",
      "INFO:tensorflow:loss = 81.38471, step = 3301 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.454\n",
      "INFO:tensorflow:loss = 86.37979, step = 3401 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.106\n",
      "INFO:tensorflow:loss = 79.71841, step = 3501 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.524\n",
      "INFO:tensorflow:loss = 86.92102, step = 3601 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.965\n",
      "INFO:tensorflow:loss = 85.82962, step = 3701 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.166\n",
      "INFO:tensorflow:loss = 84.708336, step = 3801 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.823\n",
      "INFO:tensorflow:loss = 85.263504, step = 3901 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.775\n",
      "INFO:tensorflow:loss = 91.911026, step = 4001 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.648\n",
      "INFO:tensorflow:loss = 83.04646, step = 4101 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.602\n",
      "INFO:tensorflow:loss = 84.71329, step = 4201 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.134\n",
      "INFO:tensorflow:loss = 81.37947, step = 4301 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.978\n",
      "INFO:tensorflow:loss = 79.71997, step = 4401 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.892\n",
      "INFO:tensorflow:loss = 86.36683, step = 4501 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.595\n",
      "INFO:tensorflow:loss = 87.48178, step = 4601 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.596\n",
      "INFO:tensorflow:loss = 82.491486, step = 4701 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.112\n",
      "INFO:tensorflow:loss = 85.262634, step = 4801 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.177\n",
      "INFO:tensorflow:loss = 82.49095, step = 4901 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.573\n",
      "INFO:tensorflow:loss = 81.380005, step = 5001 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.338\n",
      "INFO:tensorflow:loss = 86.37721, step = 5101 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.825\n",
      "INFO:tensorflow:loss = 85.81929, step = 5201 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.268\n",
      "INFO:tensorflow:loss = 80.83296, step = 5301 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.625\n",
      "INFO:tensorflow:loss = 84.153946, step = 5401 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.386\n",
      "INFO:tensorflow:loss = 84.154144, step = 5501 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.639\n",
      "INFO:tensorflow:loss = 83.59918, step = 5601 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.636\n",
      "INFO:tensorflow:loss = 84.70952, step = 5701 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.853\n",
      "INFO:tensorflow:loss = 78.063644, step = 5801 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.178\n",
      "INFO:tensorflow:loss = 88.022606, step = 5901 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.155\n",
      "INFO:tensorflow:loss = 86.93405, step = 6001 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.031\n",
      "INFO:tensorflow:loss = 85.26121, step = 6101 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.661\n",
      "INFO:tensorflow:loss = 84.70801, step = 6201 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.049\n",
      "INFO:tensorflow:loss = 75.84726, step = 6301 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.645\n",
      "INFO:tensorflow:loss = 89.71251, step = 6401 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.483\n",
      "INFO:tensorflow:loss = 81.93109, step = 6501 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.482\n",
      "INFO:tensorflow:loss = 82.49192, step = 6601 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.498\n",
      "INFO:tensorflow:loss = 85.26381, step = 6701 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.058\n",
      "INFO:tensorflow:loss = 81.38289, step = 6801 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.11\n",
      "INFO:tensorflow:loss = 85.81582, step = 6901 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.599\n",
      "INFO:tensorflow:loss = 80.278656, step = 7001 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.363\n",
      "INFO:tensorflow:loss = 83.04582, step = 7101 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.69\n",
      "INFO:tensorflow:loss = 80.83628, step = 7201 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.835\n",
      "INFO:tensorflow:loss = 85.266556, step = 7301 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.44\n",
      "INFO:tensorflow:loss = 83.04312, step = 7401 (0.345 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 348.124\n",
      "INFO:tensorflow:loss = 82.48874, step = 7501 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.978\n",
      "INFO:tensorflow:loss = 85.81544, step = 7601 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.079\n",
      "INFO:tensorflow:loss = 86.92778, step = 7701 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.93\n",
      "INFO:tensorflow:loss = 90.81992, step = 7801 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.208\n",
      "INFO:tensorflow:loss = 84.15419, step = 7901 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.661\n",
      "INFO:tensorflow:loss = 79.73399, step = 8001 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.85\n",
      "INFO:tensorflow:loss = 81.38554, step = 8101 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.622\n",
      "INFO:tensorflow:loss = 85.26166, step = 8201 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.415\n",
      "INFO:tensorflow:loss = 82.48974, step = 8301 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.723\n",
      "INFO:tensorflow:loss = 85.818245, step = 8401 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.74\n",
      "INFO:tensorflow:loss = 82.490326, step = 8501 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.555\n",
      "INFO:tensorflow:loss = 80.27622, step = 8601 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.799\n",
      "INFO:tensorflow:loss = 84.708694, step = 8701 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.031\n",
      "INFO:tensorflow:loss = 81.94024, step = 8801 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.593\n",
      "INFO:tensorflow:loss = 84.70863, step = 8901 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.675\n",
      "INFO:tensorflow:loss = 85.262146, step = 9001 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.365\n",
      "INFO:tensorflow:loss = 81.38516, step = 9101 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.611\n",
      "INFO:tensorflow:loss = 82.49271, step = 9201 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.847\n",
      "INFO:tensorflow:loss = 85.263535, step = 9301 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.497\n",
      "INFO:tensorflow:loss = 84.15426, step = 9401 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.748\n",
      "INFO:tensorflow:loss = 81.37827, step = 9501 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.815\n",
      "INFO:tensorflow:loss = 81.93669, step = 9601 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.468\n",
      "INFO:tensorflow:loss = 85.26527, step = 9701 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.389\n",
      "INFO:tensorflow:loss = 83.04659, step = 9801 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.554\n",
      "INFO:tensorflow:loss = 83.59986, step = 9901 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.055\n",
      "INFO:tensorflow:loss = 80.28186, step = 10001 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.201\n",
      "INFO:tensorflow:loss = 80.280075, step = 10101 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.346\n",
      "INFO:tensorflow:loss = 90.25689, step = 10201 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.134\n",
      "INFO:tensorflow:loss = 85.81958, step = 10301 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.373\n",
      "INFO:tensorflow:loss = 84.70886, step = 10401 (0.287 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10407 into Titanic_trained_DNN/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 19.516329.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x11989bc88>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTDIR_DNN = 'Titanic_trained_DNN'\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "shutil.rmtree(OUTDIR_DNN, ignore_errors = True) # start fresh each time\n",
    "model_DNN = tf.estimator.(hidden_units = [32, 8, 2],\n",
    "      feature_columns = make_feature_cols(X_train), model_dir = OUTDIR_DNN)\n",
    "model_DNN.train(input_fn = make_input_fn(X_train, y_train, num_epochs = 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-06-02-15:41:21\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from Titanic_trained_DNN/model.ckpt-10407\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-06-02-15:41:21\n",
      "INFO:tensorflow:Saving dict for global step 10407: accuracy = 0.5650224, accuracy_baseline = 0.5650224, auc = 0.5, auc_precision_recall = 0.71748877, average_loss = 0.694991, global_step = 10407, label/mean = 0.4349776, loss = 77.49149, prediction/mean = 0.36499456\n",
      "RMSE on validation dataset = 0.8336611986160278\n"
     ]
    }
   ],
   "source": [
    "print_rmse(model_DNN, 'validation', X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from Titanic_trained_DNN/model.ckpt-10407\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "New Samples, Class Predictions:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_iter = model_DNN.predict(input_fn = make_prediction_input_fn(X_test,1))\n",
    "# print([pred['predictions'][0] for pred in list(itertools.islice(preds_iter, 5))])\n",
    "predicted_classes = [np.int(p[\"classes\"]) for p in preds_iter]\n",
    "print(\"New Samples, Class Predictions:    {}\\n\".format(predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengerid = np.array(df_test.PassengerId.tolist())\n",
    "submission = pd.DataFrame({'PassengerId': passengerid, 'Survived': predicted_classes}).set_index('PassengerId')\n",
    "submission.to_csv('submission_tf_DNN_v4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> XGBoost </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTDIR_DNN = 'Titanic_trained_XGBoost'\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "shutil.rmtree(OUTDIR_DNN, ignore_errors = True) # start fresh each time\n",
    "model_XGBoost = XGBClassifier()\n",
    "model_XGBoost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8475336322869955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# print_rmse(model_DNN, 'validation', X_valid, y_valid)\n",
    "y_pred = model_XGBoost.predict(X_valid)\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "print('accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Samples, Class Predictions:    [0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 1\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0\n",
      " 0 1 1 1 1 0 0 1 0 0 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lambert/virtualenvs/tensorflow/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# preds_iter = model_DNN.predict(input_fn = make_prediction_input_fn(X_test,1))\n",
    "# print([pred['predictions'][0] for pred in list(itertools.islice(preds_iter, 5))])\n",
    "predicted_classes = model_XGBoost.predict(X_test)\n",
    "# predicted_classes = [np.int(p[\"classes\"]) for p in preds_iter]\n",
    "print(\"New Samples, Class Predictions:    {}\\n\".format(predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengerid = np.array(df_test.PassengerId.tolist())\n",
    "submission = pd.DataFrame({'PassengerId': passengerid, 'Survived': predicted_classes}).set_index('PassengerId')\n",
    "submission.to_csv('submission_tf_XGBoost_v4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow variables\n",
    "# with tf.device('/device:GPU:0'):\n",
    "features= len(sFeatures)\n",
    "X_place = tf.placeholder(tf.float32, shape=[None,features])\n",
    "y_place = tf.placeholder(tf.float32, shape=[None,2])\n",
    "W = tf.Variable(tf.random_normal([features, 2]), name='weights')\n",
    "b = tf.Variable(tf.zeros(2), name='bias')\n",
    "logits = tf.matmul(X_place, W) + b\n",
    "y_pred = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Entropy\n",
    "# with tf.device('/device:GPU:0'):\n",
    "learning_rate = 0.001\n",
    "cross_entropy = -tf.reduce_sum(y_place * tf.log(y_pred + 1e-10), axis=1)\n",
    "# cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y_train)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.Session()\n",
    "# sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training starting option 1\n",
    "# for epoch in range(10000):\n",
    "#     total_loss = 0.\n",
    "#     x_batch, y_batch = next_batch(batch_size, X_train, y_train)\n",
    "#     feed_dict_train = {X_place: x_batch, y_place: y_batch}\n",
    "#     _, loss = sess.run([train_op, cost], feed_dict=feed_dict_train)\n",
    "#     total_loss += loss\n",
    "#     print('Epoch: {:04d}, total loss={:.9f}'.format(epoch+1, total_loss))\n",
    "# #     print('Epoch: {:04d}, total loss={:.9f}, entropy: {}'.format(epoch+1, total_loss, cross_entropy))\n",
    "# #     print('predict: {:.6f}'.format(y_pred))\n",
    "# print ('Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training starting option 1 with CPU\n",
    "# for epoch in range(100):\n",
    "#     total_loss = 0.\n",
    "#     for i in range(len(X_train)):\n",
    "#         feed = {X_place: X_train, y_place: y_train}\n",
    "#         _, loss = sess.run([train_op, cost], feed_dict=feed)\n",
    "#         total_loss += loss\n",
    "#     print('Epoch: {:04d}, total loss={:.9f}'.format(epoch+1, total_loss))\n",
    "# #     print('Epoch: {:04d}, total loss={:.9f}, entropy: {}'.format(epoch+1, total_loss, cross_entropy))\n",
    "# #     print('predict: {:.6f}'.format(y_pred))\n",
    "# print ('Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training starting option 1 with GPU\n",
    "# with tf.device('/device:GPU:0'):\n",
    "start = time.time()\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(10000):\n",
    "            total_loss = 0.\n",
    "            for i in range(len(X_train)):\n",
    "                feed = {X_place: X_train, y_place: y_train}\n",
    "                _, loss = sess.run([train_op, cost], feed_dict=feed)\n",
    "                total_loss += loss\n",
    "            print('Epoch: {:04d}, total loss={:.9f}'.format(epoch+1, total_loss))\n",
    "        #     print('Epoch: {:04d}, total loss={:.9f}, entropy: {}'.format(epoch+1, total_loss, cross_entropy))\n",
    "        #     print('predict: {:.6f}'.format(y_pred))\n",
    "        print ('Training complete!')\n",
    "\n",
    "        feed_dict_train = {X_place: X_train}\n",
    "        prediction = sess.run(y_pred, feed_dict=feed_dict_train)\n",
    "        correct = np.equal(np.argmax(prediction,axis=1), np.argmax(y_train,axis=1))\n",
    "        # evaluate the accuracy\n",
    "        accuracy = np.mean(correct)\n",
    "        print('Accuracy on validation: {:2.2%}'.format (accuracy))\n",
    "    save_path = saver.save(sess, model_path+'Titanic_model.ckpt')\n",
    "end = time.time()\n",
    "print('time spend: {:.4f} sec'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = saver.save(sess, model_path+'Titanic_model.ckpt')\n",
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the training data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path+'Titanic_model.ckpt')\n",
    "    feed_dict_train = {X_place: X_train}\n",
    "    prediction = sess.run(y_pred, feed_dict=feed_dict_train)\n",
    "    correct = np.equal(np.argmax(prediction,axis=1), np.argmax(y_train,axis=1))\n",
    "# evaluate the accuracy\n",
    "accuracy = np.mean(correct)\n",
    "print('Accuracy on validation: {:2.2%}'.format (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the validate data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path+'Titanic_model.ckpt')\n",
    "    feed_dict_valid = {X_place: X_val}\n",
    "    prediction = sess.run(y_pred, feed_dict=feed_dict_valid)\n",
    "    correct = np.equal(np.argmax(prediction,axis=1), np.argmax(y_val,axis=1))\n",
    "# evaluate the accuracy\n",
    "\n",
    "accuracy = np.mean(correct)\n",
    "print('Accuracy on validation: {:2.2%}'.format (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction for test data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path+'Titanic_model.ckpt')\n",
    "    feed_dict_test = {X_place: X_test}\n",
    "    prediction = sess.run(y_pred, feed_dict=feed_dict_test)\n",
    "    y_predict = np.argmax(prediction, axis=1)\n",
    "    y_predict_1 = np.argmin(prediction, axis=1)\n",
    "    \n",
    "# evaluate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengerid = np.array(df_test.PassengerId.tolist())\n",
    "submission = pd.DataFrame({'PassengerId': passengerid, 'Survived': y_predict_1}).set_index('PassengerId')\n",
    "submission.to_csv('submission_tf_GDO_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_accuracy()\n",
    "# plot_example_errors()\n",
    "# optimize(num_iterations=10)\n",
    "# print_accuracy()\n",
    "# plot_example_errors()\n",
    "# plot_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "File_Writer=tf.summary.FileWriter(''/Users/lambert/Documents/Python_code/tensorflow_code/Titanic'\n",
    "                                  ,sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate as much GPU memory based on runtime allocations\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate 40% memory of GPU\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = tf.Session(config=config, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically choose existing in case specified one doesn't exit\n",
    "# allow_soft_placement=True\n",
    "with tf.device('/device:GPU:2'):\n",
    "  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "  c = tf.matmul(a, b)\n",
    "# Creates a session with allow_soft_placement and log_device_placement set\n",
    "# to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.random(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
